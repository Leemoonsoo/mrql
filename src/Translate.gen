/********************************************************************************
   Copyright 2011-2012 Leonidas Fegaras, University of Texas at Arlington

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

   File: Translate.gen
   Translate and optimize MRQL queries to physical plans
   Programmer: Leonidas Fegaras, UTA
   Date: 10/14/10 - 08/12/12

********************************************************************************/

package hadoop.mrql;

import Gen.*;
import java.util.*;
import java.io.*;


class Translate {
    static Trees functions = #[ ];

    static {
	ClassImporter.load_classes();
	DataSource.loadParsers();
    }

    /* type environment that binds local variables to types */
    static SymbolTable type_env = new SymbolTable();

    /* type environment that binds global variables to types */
    static SymbolTable global_type_env = new SymbolTable();

    /* type environment that binds datatype names to types */
    static SymbolTable global_datatype_env = new SymbolTable();

    /* used in pattern compilation and variable renaming */
    static SymbolTable st = new SymbolTable();

    /* binds macro names to MRQL expressions (used for 'name = expr;' syntax) */
    static SymbolTable global_vars = new SymbolTable();

    /* binds a UDF name to its plan */
    static SymbolTable global_functions = new SymbolTable();

    /* used in typedefs */
    static SymbolTable type_names = new SymbolTable();

    /* binds a data constructor name to its type */
    static SymbolTable data_constructors = new SymbolTable();

    static Trees repeat_variables = #[];

    static {
	global_type_env.insert("args",#<list(string)>);
    }

    static Trees impure_functions = #[random];

    static int var_count = 0;

    static void reset () {
	var_count = 0;
	type_env = global_type_env;
	st = new SymbolTable();
	type_env = new SymbolTable();
	repeat_variables = #[];
    }

    static void error ( String msg ) {
	System.err.println("*** MRQL error at line "+Main.parser.scanner.line_pos()+": "+msg);
	throw new Error();
    }

    final static Tree identity = #<lambda(x,x)>;

    static Tree identity () {
	return rename(#<lambda(x,bag(x))>);
    }

    // An aggeregation must be based on a commutative monoid (plus,zero) with a unit:
    //     name(type,plus,zero,unit)
    // plus: b -> b-> b, zero: b, unit: a -> b
    static Trees monoids =
	#[ count(any,lambda(x,call(plus,nth(x,0),nth(x,1))),typed(0,long),lambda(x,typed(1,long))),
	   sum(int,lambda(x,call(plus,nth(x,0),nth(x,1))),typed(0,long),lambda(x,typed(x,long))),
	   sum(long,lambda(x,call(plus,nth(x,0),nth(x,1))),typed(0,long),`identity),
	   sum(float,lambda(x,call(plus,nth(x,0),nth(x,1))),typed(0.0,double),lambda(x,typed(x,double))),
	   sum(double,lambda(x,call(plus,nth(x,0),nth(x,1))),typed(0.0,double),`identity),
	   max(int,lambda(x,call(max,nth(x,0),nth(x,1))),typed(`(Integer.MIN_VALUE),int),`identity),
	   max(long,lambda(x,call(max,nth(x,0),nth(x,1))),typed(`(Long.MIN_VALUE),long),`identity),
	   max(float,lambda(x,call(max,nth(x,0),nth(x,1))),typed(`(Float.MIN_VALUE),float),`identity),
	   max(double,lambda(x,call(max,nth(x,0),nth(x,1))),typed(`(Double.MIN_VALUE),double),`identity),
	   min(int,lambda(x,call(min,nth(x,0),nth(x,1))),typed(`(Integer.MAX_VALUE),int),`identity),
	   min(long,lambda(x,call(min,nth(x,0),nth(x,1))),typed(`(Long.MAX_VALUE),long),`identity),
	   min(float,lambda(x,call(min,nth(x,0),nth(x,1))),typed(`(Float.MAX_VALUE),float),`identity),
	   min(double,lambda(x,call(min,nth(x,0),nth(x,1))),typed(`(Double.MAX_VALUE),double),`identity),
	   avg_aggr(int,lambda(x,tuple(call(plus,nth(nth(x,0),0),nth(nth(x,1),0)),
				       call(plus,nth(nth(x,0),1),nth(nth(x,1),1)))),
		    tuple(typed(0.0,double),typed(0,long)),
		    lambda(x,tuple(typed(x,double),typed(1,long)))),
	   avg_aggr(long,lambda(x,tuple(call(plus,nth(nth(x,0),0),nth(nth(x,1),0)),
					call(plus,nth(nth(x,0),1),nth(nth(x,1),1)))),
		    tuple(typed(0.0,double),typed(0,long)),
		    lambda(x,tuple(typed(x,double),typed(1,long)))),
	   avg_aggr(float,lambda(x,tuple(call(plus,nth(nth(x,0),0),nth(nth(x,1),0)),
					 call(plus,nth(nth(x,0),1),nth(nth(x,1),1)))),
		    tuple(typed(0.0,double),typed(0,long)),
		    lambda(x,tuple(typed(x,double),typed(1,long)))),
	   avg_aggr(double,lambda(x,tuple(call(plus,nth(nth(x,0),0),nth(nth(x,1),0)),
					  call(plus,nth(nth(x,0),1),nth(nth(x,1),1)))),
		    tuple(typed(0.0,double),typed(0,long)),
		    lambda(x,tuple(typed(x,double),typed(1,long)))),
	   all(bool,lambda(x,call(and,nth(x,0),nth(x,1))),true,`identity),
	   some(bool,lambda(x,call(or,nth(x,0),nth(x,1))),false,`identity)
	   ];

    static void print_aggregates () {
	for ( Tree m: monoids )
	    match m {
	    case `f(`tp,...):
		System.out.print(" "+f+":"+print_type(tp));
	    }
	System.out.println();
    }

    static String print_type ( Tree tp ) {
	match tp {
	case tuple(...tl):
	    if (tl.is_empty())
		return "()";
	    String s = "( "+print_type(tl.head());
	    for ( Tree t: tl.tail() )
		s += ", "+print_type(t);
	    return s+" )";
	case record(...tl):
	    if (tl.is_empty())
		return "< >";
	    String s = "< ";
	    match tl.head() {
	    case bind(`a,`t):
		s += a+": "+print_type(t);
	    };
	    for ( Tree t: tl.tail() )
		match t {
		case bind(`a,`at):
		    s += ", "+a+": "+print_type(at);
		};
	    return s+" >";
	case arrow(`itp,`otp):
	    return print_type(itp)+" -> "+print_type(otp);
	case persistent(`t):
	    return "!"+print_type(t);
	case `f():
	    return f+"()";
	case persistent(`t):
	    return "!"+print_type(t);
	case Bag(`etp):
	    return "!bag("+print_type(etp)+")";
	case List(`etp):
	    return "!list("+print_type(etp)+")";
	case `f(...tl):
	    String s = f+"( "+print_type(tl.head());
	    for ( Tree t: tl.tail() )
		s += ", "+print_type(t);
	    return s+" )";
	};
	return tp.toString();
    }

    public static String print_query_list ( Trees el ) {
	if (el.length() == 0)
	    return "";
	String s = " ";
	s += print_query(el.head());
	for ( Tree a: el.tail() )
	    s += ", "+print_query(a);
	return s+" ";
    }

    public static String print_query ( Tree e ) {
        match e {
	case select(`opt_dist,`u,from(...bl),where(`c),groupby(...gs),orderby(...os)):
	    String s = "select "+(opt_dist.equals(#<none>) ? "" : "distinct ");
	    s += print_query(u)+" from ";
	    match bl.head() {
	    case bind(`p,`d):
		s += print_query(p)+" in "+print_query(d);
	    };
	    for ( Tree b: bl.tail() )
		match b {
		case bind(`p,`d):
		    s += ", "+print_query(p)+" in "+print_query(d);
		};
	    if (!c.equals(#<true>))
		s += " where "+print_query(c);
	    match #<groupby(...gs)> {
	    case groupby(`h,...gl):
		s += " group by ";
		match gl.head() {
		case bind(`gp,`gd):
		    s += print_query(gp)+": "+print_query(gd);
		};
		for ( Tree g: gl.tail() )
		    match g {
		    case bind(`gp,`gd):
			s += ", "+print_query(gp)+": "+print_query(gd);
		    };
		if (!h.equals(#<true>))
		    s += " having "+print_query(h);
	    };
	    match #<orderby(...os)> {
	    case orderby(`l,...ol):
		s += " order by "+print_query(ol.length() == 1 ? ol.head() : #<tuple(...ol)>);
		if (!l.equals(#<none>))
		    s += " limit "+print_query(l);
	    };
	    return s;
	case tuple(...el):
	    return "("+print_query_list(el)+")";
	case record(...el):
	    String s = "< ";
	    match el.head() {
	    case bind(`v,`b):
		s += v+": "+print_query(b);
	    };
	    for ( Tree a: el.tail() )
		match a {
		case bind(`v,`b):
		    s += ", "+v+": "+print_query(b);
		};
	    return s+" >";
	case project(`a,`v):
	    return (a.is_variable()) ? print_query(a)+"."+v : "("+print_query(a)+")."+v;
	case index(`a,`i):
	    return (a.is_variable()) ? print_query(a)+"["+print_query(i)+"]"
		                     : "("+print_query(a)+")["+print_query(i)+"]";
	case nth(`x,`n):
	    return (x.is_variable()) ? print_query(x)+"#"+print_query(n)
	                             : "("+print_query(x)+")#"+print_query(n);
	case call(`f,...el):
	    return f+"("+print_query_list(el)+")";
	case list(...el):
	    return "["+print_query_list(el)+"]";
	case bag(...el):
	    return "{"+print_query_list(el)+"}";
	case `f(...el):
	    return f+"("+print_query_list(el)+")";
	};
	return e.toString();
    }

    // generates new variable names
    static Tree new_var () {
	return new VariableLeaf("x_"+(Integer.toString(var_count++)));
    }

    static boolean is_pure ( Tree expr ) {
	match expr {
	case call(`f,...al):
	    if (impure_functions.member(f))
		return false;
	    else fail
	case `f(...al):
	    for ( Tree a: al )
		if (!is_pure(a))
		    return false;
	};
	return true;
    }

    // replace all occurences of from_expr in expr with to_expr
    static Tree subst ( Tree from_expr, Tree to_expr, Tree expr ) {
	if (expr.equals(from_expr))
	    return to_expr;
	match expr {
	case lambda(`v,_):
	    if (pattern_variables(v).member(from_expr))
		return expr;
	    else fail
	case `f(...al):
	    return #<`f(...(subst_list(from_expr,to_expr,al)))>;
	};
	return expr;
    }

    static Trees subst_list ( Tree from_expr, Tree to_expr, Trees el ) {
	Trees bl = #[];
	for ( Tree e: el )
	    bl = bl.append(subst(from_expr,to_expr,e));
	return bl;
    }

    static Tree subst_var ( Tree var, Tree to_expr, Tree expr ) {
	if (!is_pure(to_expr) && occurences(var,expr) > 1)
	    return #<let(`var,`to_expr,`expr)>;
	else return subst(var,to_expr,expr);
    }

    public static Tree template ( Tree s ) {
    	match s {
	case template(`parser,...as):
	    try {
		Trees args = #[];
		String tx = "";
		int i = 0;
		for ( Tree a: as )
		    match a {
		    case text(`t): tx += t;
		    case _: args = args.append(a);
			    tx += "{{"+(i++)+"}}";
		    };
		Class<? extends Parser> pc = DataSource.parserDirectory.get(parser.toString());
		if (pc == null)
		    throw new Error("Unrecognized parser: "+parser);
		Parser p = pc.newInstance();
		p.initialize(#[]);
		Bag e = p.parse(tx);
		Tree res = Interpreter.reify(e.get(0),p.type());
		for ( int j = 0; j < i; j++ )
		    res = subst(new VariableLeaf("t_"+j),args.nth(j),res);
		return res;
	    } catch (Exception e) {
		throw new Error("Wrong template: "+s+"\n"+e);
	    }
        };
	throw new Error("Wrong template: "+s);
    }

    public static String reify ( Tree e ) {
	if (e instanceof LongLeaf)
	    return "new Gen.LongLeaf(" + e + ")";
	else if (e instanceof DoubleLeaf)
	    return "new Gen.DoubleLeaf(" + e + ")";
	else if (e instanceof VariableLeaf)
	    return "new Gen.VariableLeaf(\"" + e.variableValue() + "\")";
	else if (e instanceof StringLeaf)
	    return "new Gen.StringLeaf(" + e.toString().replace("\\","\\\\") + ")";
	else {
	    Node n = (Node) e;
	    return "new Gen.Node(\""+n.name()+"\","+reify(n.children())+")";
	}
    }

    public static String reify ( Trees ts ) {
	String s = "Gen.Trees.nil";
	for ( Tree c: ts )
	    s += ".append("+reify(c)+")";
	return s;
    }

    // return the list of free variables in e that are not in exclude
    public static Trees free_variables ( Tree e, Trees exclude ) {
	if (e == null)
	    return #[];
	match e {
	case lambda(`x,`b):
	    return free_variables(b,exclude.append(pattern_variables(x)));
	case let(`x,`u,`b):
	    return free_variables(b,exclude.append(pattern_variables(x)))
		     .append(free_variables(u,exclude));
	case Let(`x,`u,`b):
	    return free_variables(b,exclude.append(pattern_variables(x)))
		     .append(free_variables(u,exclude));
	case select(`u,from(...bs),`p):
	    Trees ex = exclude;
	    Trees fs = #[];
	    for ( Tree b: bs )
		match b {
		case bind(`v,`x):
		    fs = fs.append(free_variables(x,ex));
		    ex = ex.append(pattern_variables(v));
		};
	    return free_variables(p,ex).append(free_variables(u,ex)).append(fs);
	case `f(...as):
	    Trees res = #[];
	    for ( Tree a: as )
		res = res.append(free_variables(a,exclude));
	    return res;
	case `v:
	    if (v.is_variable() && v.toString().startsWith("x_") && !exclude.member(v))
	        return #[`v];
	};
	return #[];
    }

    // count the occurences of x in e
    public static int occurences ( Tree x, Tree e ) {
	if (x.equals(e))
	    return 1;
	match e {
	case `f(...as):
	    int i = 0;
	    for ( Tree a: as )
		i += occurences(x,a);
	    return i;
	};
	return 0;
    }

    // return true if x is equal to y modulo variable substitution
    public static boolean alpha_equivalent ( Tree x, Tree y, SymbolTable st ) {
	match #<T(`x,`y)> {
	case T(lambda(`vx,`bx),lambda(`vy,`by)):
	    if (!vx.equals(vy))
		st.insert(vx.toString(),vy);
	    return alpha_equivalent(bx,by,st);
	case T(`f(...xs),`g(...ys)):
	    if (!f.equals(g) || xs.length() != ys.length())
		return false;
	    for ( ; !xs.is_empty(); xs = xs.tail(), ys = ys.tail() )
		if (!alpha_equivalent(xs.head(),ys.head(),st))
		    return false;
	    return true;
	case T(`v,`w):
	    if (v.is_variable() && w.is_variable())
	        return v.equals(w) || (st.lookup(v.toString()) != null
				       && st.lookup(v.toString()).equals(w));
	};
	return x.equals(y);
    }

    static SymbolTable alpha_symbol_table = new SymbolTable();

    public static boolean alpha_equivalent ( Tree x, Tree y ) {
	alpha_symbol_table.begin_scope();
	boolean b = alpha_equivalent(x,y,alpha_symbol_table);
	alpha_symbol_table.end_scope();
	return b;
    }

    static Tree make_and ( Trees tests ) {
        if (tests.is_empty())
	    return #<true>;
	Tree e = tests.head();
	for ( Tree t: tests.tail() )
	    e = #<call(and,`e,`t)>;
	return e;
    }

    static Trees union ( Trees xs, Trees ys ) {
	Trees res = xs;
	for ( Tree y: ys )
	    if (!xs.member(y))
		res = res.append(y);
	return res;
    }

    // return the variables of a pattern
    static Trees pattern_variables ( Tree pattern ) {
        Trees args = #[];
	match pattern {
	case tuple(...pl):
	    for ( Tree p: pl )
		args = union(args,pattern_variables(p));
        case record(...bl):
	    for ( Tree b: bl )
		match b {
		case bind(`n,`p):
		    args = union(args,pattern_variables(p));
		};
	case typed(`p,_):
	    args = pattern_variables(p);
	case `v:
	    if (v.is_variable())
		args = #[`v];
	};
	return args;
    }

    static Tree normalize_type ( Tree type ) {
	match type {
	case record(...bs):
	    Trees as = #[];
	    Trees vs = #[];
	    for ( Tree b: bs )
		match b {
		case bind(`v,`tp):
		    if (v.is_variable())
			if (vs.member(v))
			    type_error(type,"Duplicate record attributes: "+print_type(type));
			else {
			    vs = vs.append(v);
			    as = as.append(#<bind(`v,`(normalize_type(tp)))>);
			}
		    else type_error(type,"Expected an attribute name: "+v);
		case _: type_error(type,"Ill-formed record type: "+print_type(type));
		};
	    return #<record(...as)>;
	case tuple(...ts):
	    Trees as = #[];
	    for ( Tree t: ts )
		as = as.append(normalize_type(t));
	    return #<tuple(...as)>;
	case union(...bs):
	    Trees as = #[];
	    for ( Tree b: bs )
		match b {
		case `c(`tp):
		    as = as.append(#<`c(`(normalize_type(tp)))>);
		case _: type_error(type,"Ill-formed union type: "+print_type(type));
		};
	    return #<union(...as)>;
	case persistent(bag(`tp)):
	    Tree ntp = normalize_type(tp);
	    return #<Bag(`ntp)>;
	case persistent(list(`tp)):
	    Tree ntp = normalize_type(tp);
	    return #<List(`ntp)>;
	case `T(`tp):
	    if (is_collection(T))
		return #<`T(`(normalize_type(tp)))>;
	    else fail
	case `tp:
	    if (!tp.is_variable())
		fail;
	    if (#[bool,byte,short,int,long,float,double,string].member(tp))
		return tp;
	    Tree rt = global_datatype_env.lookup(tp.toString());
	    if (rt != null)
		return tp;
	    rt = type_names.lookup(tp.toString());
	    if (rt != null)
		return tp;
	};
	type_error(type,"Unrecognized type: "+print_type(type));
	return type;
    }

    // given that patter=e, find the bindings of the pattern variables
    static Trees bind_pattern ( Tree pattern, Tree e ) {
        Trees args = #[];
	match pattern {
	case tuple(...pl):
	    int i = 0;
	    for ( Tree p: pl ) {
		args = args.append(bind_pattern(p,#<nth(`e,`i)>));
		i++;
	    }
        case record(...bl):
	    Trees attrs = #[];
	    for ( Tree b: bl )
		match b {
		case bind(`n,`p):
		    args = args.append(bind_pattern(p,#<project(`e,`n)>));
		    if (attrs.member(n))
			type_error(pattern,"Duplicate record attribute name: "+n);
		    attrs = attrs.append(n);
		};
	case typed(`p,`t):
	    args = bind_pattern(p,#<typed(`e,`t)>);
	case list(...pl):
	    int i = 0;
	    for ( Tree p: pl ) {
		args = args.append(bind_pattern(p,#<index(`e,`i)>));
		i++;
	    };
	    args = args.append(#<call(eq,call(count,`e),`i)>);
	case call(`c,...s):
	    Tree ci = data_constructors.lookup(c.toString());
	    if (ci == null)
		type_error(pattern,"Undefined data constructor: "+c);
	    match ci {
	    case `dname(`n,`tp):
		args = args.append(#<call(eq,union_tag(`e),`n)>);
		args = args.append(bind_pattern(s.length() == 1 ? s.head() : #<tuple(...s)>,
						#<typed(union_value(`e),`tp)>));
	    };
        case any: ;
	case `v:
	    if (!v.is_variable())    // constant in pattern
		args = #[call(eq,`e,`v)];
	    else if (st.lookup(v.toString()) != null    // repeated pattern variable
		     && !(e.is_variable() && st.lookup(v.toString()).is_variable()))  // exception
		args = #[call(eq,`e,`(st.lookup(v.toString())))];
	    else st.insert(v.toString(),e);    // new pattern variable
	};
	return args;
    }

    static Tree make_tuple ( Trees pl ) {
    	if (pl.length() == 1)
	    return pl.head();
	return #<tuple(...pl)>;
    }

    // remove group-bys and order-bys from the MRQL queries
    static Tree remove_groupby ( Tree e ) {
    	Tree ret = #<error>;
	match e {
	case select(distinct,`u,from(...bl),where(`c),groupby(...gl),orderby(...ol)):
	    ret = #<select(none,tuple(`u,`u),from(...bl),where(`c),groupby(...gl),orderby(...ol))>;
	    ret = #<cmap(lambda(tuple(key,group),list(key)),groupBy(`ret))>;
	    return remove_groupby(ret);
	case select(none,`u,from(...bl),where(`c),groupby(),orderby()):
	    return remove_groupby(#<select(`u,from(...bl),where(`c))>);
	case select(none,`u,from(...bl),where(`c),groupby(...gl),orderby(`l,...ol)):
	    Tree tol = make_tuple(ol);
	    ret = #<cmap(lambda(tuple(key,group),group),
			 orderBy(select(none,tuple(`tol,`u),
					from(...bl),
					where(`c),groupby(...gl),orderby())))>;
	    return (l.equals(#<none>))
		   ? remove_groupby(ret)
		   : #<range(`(remove_groupby(ret)),0,`l)>;
	case select(none,`u,from(...bl),where(`c),groupby(`h,...gl),orderby()):
	    Trees pl = #[];
	    Trees ul = #[];
	    Trees ql = #[];
	    for ( Tree b: bl )
		match b {
		case bind(`p,`d):
		    pl = pl.append(p);
		};
	    for ( Tree g: gl )
		match g {
		case bind(`p,`d):
		    ql = ql.append(p);
		    ul = ul.append(d);
		};
	    Tree tql = make_tuple(ql);
	    Tree tul = make_tuple(ul);
	    Tree tpl = make_tuple(pl);
	    Trees xl = #[];
	    for ( Tree x: pattern_variables(#<tuple(...pl)>) )
		match rename(#<select(`x,from(bind(`tpl,group)),where(true))>) {
		case select(`hd,`binds,...):
		    xl = xl.append(#<bind(`x,bag(select(`hd,`binds,where(true))))>);
		};
	    tpl = subst(#<any>,#<0>,tpl);
	    ret = #<select(`u,from(bind(tuple(`tql,group),
					groupBy(select(tuple(`tul,`tpl),from(...bl),where(`c)))),
				   ...xl),where(`h))>;
	    return remove_groupby(ret);
	case intersect(`x,`y):
	    return remove_groupby(#<select(x,from(bind(x,`x),bind(y,`y)),
					   where(call(eq,x,y)))>);
	case except(`x,`y):
	    return remove_groupby(#<select(x,from(bind(x,`x)),
					   where(call(not,call(exists,select(y,from(bind(y,`y)),
									     where(call(eq,x,y)))))))>);
	case member(`x,`y):
	    return remove_groupby(#<call(exists,select(y,from(bind(y,`y)),
						       where(call(eq,y,`x))))>);
	case call(gen,`min,`max,`size):
	    return #<gen(`(remove_groupby(min)),`(remove_groupby(max)),`(remove_groupby(size)))>;
	case call(avg,`s):
	    return remove_groupby(#<call(avg_value,call(avg_aggr,`s))>);
	case call(`f,...al):
	    if (#[cmap,join,mapReduce,mapReduce2,groupBy,orderBy,tuple,bag,list,set].member(f))
		return remove_groupby(#<`(f.toString())(...al)>);
	    else fail
	case project(`x,`a):
	    return #<project(`(remove_groupby(x)),`a)>;
	case `f(...al):
	    Trees bl = #[];
	    for ( Tree a: al )
		bl = bl.append(remove_groupby(a));
	    return #<`f(...bl)>;
	case `v:
	    if (v.is_variable()) {
		ret = global_vars.lookup(v.toString());
		if (ret == null)
		    return v;
		else if (!v.equals(ret))
		    return remove_groupby(ret);
	    }
	};
	return e;
    }

    static Trees rename_list ( Trees al ) {
	Trees bl = #[];
	for ( Tree a: al )
	    bl = bl.append(rename(a));
	return bl;
    }

    // compile away patterns and rename local variables of an MRQL expression e with unique names
    static Tree rename ( Tree e ) {
    	Tree ret = #<error>;
	match e {
	case `v:
	    if (!v.is_variable())
		fail;
	    ret = st.lookup(v.toString());
	    if (ret==null)
		return v;
	    else return ret;
	case select(`u,from(...bl),where(`c)):
	    st.begin_scope();
	    Trees binds = #[];
	    Trees tests = #[];
	    for ( Tree b: bl )
		match b {
		case bind(`p,`d):
		    Tree x = new_var();
		    binds = binds.append(#<bind(`x,`(rename(d)))>);
		    tests = tests.append(bind_pattern(p,x));
		};
	    c = make_and(tests.cons(c));
	    ret = #<select(`(rename(u)),
			   from(...binds),
			   where(`(rename(c))))>;
	    st.end_scope();
	    return ret;
        case lambda(`p,`b):
	    st.begin_scope();
	    Tree nv = new_var();
	    if (!bind_pattern(p,nv).is_empty())
		type_error(e,"Lambda patterns must be irrefutable: "+print_query(e));
	    ret = #<lambda(`nv,`(rename(b)))>;
	    st.end_scope();
	    return ret;
       case function(tuple(...params),`outp,`body):
	    st.begin_scope();
	    Trees ps = #[];
	    Trees vs = #[];
	    for ( Tree p: params )
		match p {
		case `bind(`v,`tp):
		    Tree nv = new_var();
		    if (vs.member(v))
			type_error(p,"Duplicate function parameters: "+print_query(e));
		    vs = vs.append(v);
		    ps = ps.append(#<`bind(`nv,`tp)>);
		    st.insert(v.toString(),nv);
		};
	    ret = #<function(tuple(...ps),`outp,`(rename(body)))>;
	    st.end_scope();
	    return ret;
	case let(`p,`u,`b):
	    Tree ne = rename(u);
	    st.begin_scope();
	    Tree nv = new_var();
	    if (!bind_pattern(p,nv).is_empty())
		type_error(e,"Let patterns must be irrefutable: "+print_query(e));
	    ret = #<let(`nv,`ne,`(rename(b)))>;
	    st.end_scope();
	    return ret;
	case case(`u,...cs):
	    Trees rs = cs.reverse();
	    Tree nu = rename(u);
	    match rs.head() {
	    case case(`p,`b):
		Trees conds = bind_pattern(p,nu);
		if (!conds.is_empty())
		    type_error(e,"Non-exhaustive case "+print_query(p)+" in "+print_query(e));
		ret = b;
	    };
	    for ( Tree c: rs.tail() )
		match c {
		case case(`p,`b):
		    Trees conds = bind_pattern(p,nu);
		    if (!conds.is_empty())
			ret = #<if(`(make_and(conds)),`b,`ret)>;
		    else type_error(e,"Unreachable case "+print_query(p)+" in "+print_query(e));
		};
	    return rename(ret);
	case project(`u,`a):
	    return #<project(`(rename(u)),`a)>;
	case `f(...al):
	    Trees bl = rename_list(al);
	    return #<`f(...bl)>;
	};
	return e;
    }

    static Trees has_existential ( Tree e ) {
	match e {
        case call(and(`x,`y)):
	    Trees xs = has_existential(x);
	    Trees ys = has_existential(y);
	    return #[call(and(`(xs.head()),`(ys.head())),...(xs.tail()),...(ys.tail()))];
	case call(exists,select(...)):
	    return #[true,`e];
	case call(not,call(all,select(...l))):
	    return #[true,call(exists,select(...l))];
	};
	return #[`e];
    }

    static Tree normalize ( Tree e ) {
	match e {
	case select(`u,from(),where(true)):
	    return normalize(#<bag(`u)>);
	case select(`u,from(),where(`p)):
	    return normalize(#<if(`p,bag(`u),bag())>);
	case select(`u,from(bind(`v,`d)),where(true)):
	    if (u.equals(v))
		return normalize(d);
	    else fail
	case select(`u,from(...bl,bind(`v,select(`iu,from(...ibl),where(`ic))),...al),where(`c)):
	    return normalize(#<select(`u,from(...bl,...ibl,bind(`v,bag(`iu)),...al),
				      where(call(and,`c,`ic)))>);
        case select(`u,from(...bl,bind(`v,bag(`d)),...al),`c):
	    if (!is_pure(d) && occurences(v,#<f(`c,`u,...al)>) > 1)
		fail;
	    return normalize(#<select(`(subst(v,d,u)),
				      from(...bl,...(subst_list(v,d,al))),
				      `(subst(v,d,c)))>);
        case select(`u,from(...bl),where(`c)):
	    Trees es = has_existential(c);
	    if (es.length() <= 1)
		fail;
	    Trees binds = bl;
	    Trees preds = #[`(es.head())];
	    for ( Tree x: es.tail() )
		match x {
		case call(exists,select(`p,from(...bl2),where(`c2))):
		    preds = preds.cons(p).cons(c2);
		    binds = binds.append(bl2);
		};
	    return normalize(#<select(`u,from(...binds),where(`(make_and(preds))))>);
	case let_bind(`v,`x,`y):
	    return #<let(`v,`(normalize(x)),`(normalize(y)))>;
	case call(eq,tuple(...l),`x):
	    Tree pl = #<true>;
	    int i = 0;
	    for ( Tree y: l ) {
		pl = #<call(and,`pl,call(eq,`y,nth(`x,`i)))>;
		i++;
	    };
	    return normalize(pl);
	case call(eq,`x,tuple(...l)):
	    Tree pl = #<true>;
	    int i = 0;
	    for (Tree y: l) {
		pl = #<call(and,`pl,call(eq,nth(`x,`i),`y))>;
		i++;
	    };
	    return normalize(pl);
        case call(and,true,`u): return normalize(u);
        case call(and,`u,true): return normalize(u);
        case call(and,false,`u): return #<false>;
        case call(and,`u,false): return #<false>;
        case call(or,true,`u): return #<true>;
        case call(or,`u,true): return #<true>;
        case call(or,false,`u): return normalize(u);
        case call(or,`u,false): return normalize(u);
	case call(not,true): return #<false>;
	case call(not,false): return #<true>;
	case if(true,`e1,`e2): return normalize(e1);
	case if(false,`e1,`e2): return normalize(e2);
	case nth(tuple(...al),`n):
	    if (!n.is_long())
		fail;
	    int i = (int)n.longValue();
	    if ( i >= 0 && i < al.length() )
		return normalize(al.nth(i));
	case project(record(...bl),`a):
	    for ( Tree b: bl )
		match b {
		case bind(`v,`u): if (v.equals(a)) return normalize(u);
		};
	    error("Wrong projection: "+print_query(e));
	case `f(...al):
	    Trees bl = #[];
	    for ( Tree a: al )
		bl = bl.append(normalize(a));
	    return #<`f(...bl)>;
	};
	return e;
    }

    static Tree normalize_all ( Tree e ) {
	Tree ne = normalize(e);
	if (e.equals(ne))
	    return e;
	else return normalize(ne);
    }

    static boolean is_collection ( String x ) {
   	return x.equals("Bag") || x.equals("bag") || x.equals("List") || x.equals("list");
    }

    static boolean is_persistent_collection ( String x ) {
   	return x.equals("Bag") || x.equals("List");
    }

    static String persistent_collection ( String x ) {
	return (x.equals("list")) ? "List" : (x.equals("bag")) ? "Bag" : x;
    }

    static String transient_collection ( String x ) {
	return (x.equals("List")) ? "list" : (x.equals("Bag")) ? "bag" : x;
    }

    static boolean collection_type ( Tree tp ) {
   	match tp {
	case `T(`t1): return is_collection(T);
        };
	return false;
    }

    static String max_collection ( String x, String y ) {
	boolean is_bag = x.equals("Bag") || y.equals("Bag") || x.equals("bag") || y.equals("bag");
	boolean is_persistent = x.equals("Bag") || y.equals("Bag") || x.equals("List") || y.equals("List");
	return (is_bag) ? ((is_persistent) ? "Bag" : "bag") : ((is_persistent) ? "List" : "list");
    }

    static boolean numerical ( String tp ) {
	return #[short,int,long,float,double].member(#<`tp>);
    }

    static byte[] relational_record ( Tree tp ) {
	match tp {
	case record(...al):
	    Trees attrs = #[];
	    byte[] types = new byte[al.length()];
	    for ( int i = 0; i < types.length; i++ )
		match al.nth(i) {
		case bind(`v,any):
		    types[i] = -1;
		    if (attrs.member(v))
			type_error(tp,"Duplicate record attribute name: "+v);
		    attrs = attrs.append(v);
		case bind(`v,`t):
		    if (!t.is_variable())
			fail;
		    types[i] = MRContainer.type_code(t.toString());
		    if (attrs.member(v))
			type_error(tp,"Duplicate record attribute name: "+v);
		    attrs = attrs.append(v);
		    if (!MRContainer.basic_type(types[i]))
			error("Expected a basic type for a relational attribute: "+t);
		case `t: error("Expected a basic type for a relational attribute: "+print_type(t));
		};
	    return types;
	case tuple(...al):
	    byte[] types = new byte[al.length()];
	    for ( int i = 0; i < types.length; i++ )
		match al.nth(i) {
		case any:
		    types[i] = -1;
		case `t:
		    if (!t.is_variable())
			fail;
		    types[i] = MRContainer.type_code(t.toString());
		    if (!MRContainer.basic_type(types[i]))
			error("Expected a basic type for a relational attribute: "+t);
		case `t: error("Expected a basic type for a relational attribute: "+print_type(t));
		};
	    return types;
	};
	error("Expected a relational record or a tuple type: "+print_type(tp));
	return null;
    }

    static Tree relational_record_type ( Tree tp ) {
	match tp {
	case record(...al):
	    Trees ts = #[];
	    for ( Tree a: al )
		match a {
		case bind(_,any): ;
		case `t: ts = ts.append(t);
		};
	    return #<record(...ts)>;
	case tuple(...al):
	    Trees ts = #[];
	    for ( Tree a: al )
		if (!a.equals(#<any>))
		    ts = ts.append(a);
	    return #<tuple(...ts)>;
	};
	error("Expected a relational record type: "+print_type(tp));
	return null;
    }

    static void type_error ( Tree e, String msg ) {
	System.err.println("*** Type error (line: "+e.line+", position: "+e.position+")");
	if (Config.trace && type_env.iterator().hasNext()) {
	    msg += "\nVariable Types:";
	    for ( String var: type_env )
		msg += "\n "+var + ": " + print_type(type_env.lookup(var));
	};
	System.err.println("*** "+msg);
	throw new Error("Type Error");
    }

    // given that pattern has type tp, bind the pattern variables to types
    static Trees bind_pattern_type ( Tree pattern, Tree tp ) {
        Trees args = #[];
	match pattern {
	case tuple(...pl):
	    match tp {
	    case tuple(...tl):
		if (tl.length() != pl.length())
		    type_error(pattern,"Tuple pattern "+print_query(pattern)+" must have exactly "
			       +tl.length()+" components");
		int i = 0;
		for ( Tree p: pl )
		    args = args.append(bind_pattern_type(p,tl.nth(i++)));
	    case `etp: type_error(pattern,"Wrong pattern: found "+print_query(pattern)
				  +" but expected a pattern that matches the type "+print_type(etp));
	    };
        case record(...bl):
	    Trees attrs = #[];
	    match tp {
	    case record(...tl):
		for ( Tree b: bl )
		    match b {
		    case bind(`n,`p):
			boolean found = false;
			if (attrs.member(n))
			    type_error(pattern,"Duplicate record attribute name: "+n
				       +" in pattern "+print_query(pattern));
			attrs = attrs.append(n);
			for ( Tree t: tl )
			    match t {
			    case bind(`nt,`pt):
				if (!nt.equals(n))
				    fail;
				found = true;
				args = args.append(bind_pattern_type(p,pt));
			    };
			if (!found)
			    type_error(pattern,"Wrong record component: "+n
				       +" in pattern "+print_query(pattern)
				       +" (expected one from "+print_type(tp)+")");
		    };
	    case `etp: type_error(pattern,"Wrong pattern: found "+print_query(pattern)
				  +" but expected a pattern that matches the type "+print_type(etp));
	    };
	case typed(`p,`t):
	    if (subtype(t,tp))
		args = bind_pattern_type(p,t);
	    else type_error(pattern,"Type "+print_type(t)+" in pattern "+print_query(pattern)
			    +" does not match the expected type "+print_type(tp));
	case list(...pl):
	    match tp {
	    case list(`etp):
		for ( Tree p: pl )
		    args = args.append(bind_pattern_type(p,etp));
	    case `stp: type_error(pattern,"List pattern "+print_query(pattern)
				  +" can only be used for lists (found "+print_type(tp)+")");
	    };
	case call(`c,...s):
	    Tree ci = data_constructors.lookup(c.toString());
	    if (ci == null)
		type_error(pattern,"Undefined data constructor "+c+" in pattern "+print_query(pattern));
	    match ci {
	    case `dname(`n,`dtp):
		if (!subtype(tp,expand(#<`dname>)))
		    type_error(pattern,"Cannot use the data constructor "+print_query(pattern)
			       +" in a pattern that expects type "+print_type(tp));
		args = args.append(bind_pattern_type(s.length() == 1 ? s.head() : #<tuple(...s)>,
						     dtp));
	    };
        case any: ;
	case `v: 
	    if (v.is_variable()) {
		args = args.append(v);
		type_env.insert(v.toString(),tp);
	    } else if (!subtype(type_inference2(v),tp))
		type_error(pattern,"The constant "+v+" in pattern "
			   +print_query(pattern)+" is not of type "+print_type(tp));
	};
	return args;
    }

    static short needs_coerce ( Tree x, Tree y ) {
	if (x.is_variable() && numerical(x.toString())
	    && y.is_variable() && numerical(y.toString())) {
	    short cx = MRContainer.type_code(x.toString());
	    short cy = MRContainer.type_code(y.toString());
	    return (cx == cy) ? -1 : (cx > cy) ? cx : cy;
	};
	return -1;
    }

    static int collection_order ( String T ) {
	return (T.equals("List") ? 0
		: (T.equals("list") ? 1
		: (T.equals("Bag") ? 2
		: (T.equals("bag") ? 3 : -1))));
    }

    static boolean equal_types ( Tree tx, Tree ty ) {
	tx = expand(tx);
	ty = expand(ty);
	if (tx.equals(ty))
	    return true;
	match tx {
	case `f(...xs):
	    match ty {
	    case `g(...ys):
		if (f.equals(g) && xs.length() == ys.length()) {
		    for ( ; !ys.is_empty(); xs = xs.tail(), ys = ys.tail() )
			if (!equal_types(xs.head(),ys.head()))
			    return false;
		    return true;
		}
	    }
	};
	return false;
    }

    static boolean subtype ( String S, String T ) {
	return collection_order(S) <= collection_order(T);
    }

    static boolean subtype ( Tree tx, Tree ty ) {
	tx = expand(tx);
	ty = expand(ty);
	if (ty.equals(#<any>))
	    return true;
	if (equal_types(tx,ty))
	    return true;
	if (tx.is_variable() && numerical(tx.toString())
	    && ty.is_variable() && numerical(ty.toString()))
	    return MRContainer.type_code(tx.toString()) <= MRContainer.type_code(ty.toString());
	match tx {
	case `T(`tex):
	    if (!is_collection(T))
		fail;
	    match ty {
	         case `S(`tey):
		     if (is_collection(S))
	                 return subtype(T,S) && subtype(tex,tey);
		     else fail
	    };
	case union(...):
	    if (ty.equals(#<union>)) // used for XML functions
		return true;
	    else fail
	case `f(...xs):
	    match ty {
	    case `g(...ys):
		if (f.equals(g))
		    return subtype(xs,ys);
	    }
	};
	return false;
    }

    static boolean subtype ( Trees ts1, Trees ts2 ) {
   	if (ts1.length() != ts2.length())
	    return false;
	for ( Trees s1 = ts1, s2 = ts2; !s1.is_empty(); s1=s1.tail(), s2=s2.tail() )
	    if (!subtype(s1.head(),s2.head()))
		return false;
	return true;
    }

    // if the expression at loc.head has type tx that is a subtype of ty, coerce it to ty
    // NOTE: it destructively changes the expression at loc
    static void coerce ( Tree tx, Tree ty, Trees loc ) {
	tx = expand(tx);
	ty = expand(ty);
	if (ty.equals(#<any>) || equal_types(tx,ty))
	    return;
	if (tx.is_variable() && numerical(tx.toString())
	    && ty.is_variable() && numerical(ty.toString())) {
	    loc.head = #<call(coerce,`(loc.head),            // destructive
			      `(MRContainer.type_code(ty.toString())))>;
	    return;
	};
	match tx {
	case `T(`tex):
	    if (!is_collection(T))
		fail;
	    match ty {
	         case `S(`tey):
		     if (!is_collection(S))
			 fail;
		     if (is_persistent_collection(T) && !is_persistent_collection(S))
			 loc.head = #<Collect(`(loc.head))>;   // destructive
		     if (subtype(tex,tey) && unify(tex,tey) == null) {
			 Tree nv = new_var();
			 Tree b = #<bag(`nv)>;
			 coerce(tex,tey,((Node)b).children);
			 loc.head = #<cmap(lambda(`nv,`b),`(loc.head))>;   // destructive
			 return;
		     }
	    };
	case tuple(...xs):
	    match ty {
	    case tuple(...ys):
		Tree nv = new_var();
		Trees nt = #[];
		int i = 0;
		for ( Trees xl = xs, yl = ys; xl != #[] && yl != #[]; xl = xl.tail, yl = yl.tail ) {
		    Trees dest = #[nth(`nv,`(i++))];
		    coerce(xl.head,yl.head,dest);
		    nt = nt.append(dest);
		};
		loc.head = #<let(`nv,`(loc.head),tuple(...nt))>;   // destructive
	    }
	case record(...xs):
	    match ty {
	    case record(...ys):
		Tree nv = new_var();
		Trees nt = #[];
		for ( Tree x: xs )
		    match x {
		    case bind(`ax,`tex):
			for ( Tree y: ys )
			    match y {
			    case bind(`ay,`tey):
				if (equal_types(ax,ay)) {
				    Tree b = #<bind(`ax,project(`nv,`ax))>;
				    nt = nt.append(b);
				    coerce(tex,tey,((Node)b).children.tail);
				}
			    }
		    };
		loc.head = #<let(`nv,`(loc.head),record(...nt))>;   // destructive
	    }
	}
    }	

    static Trees unify ( Trees ts1, Trees ts2 ) {
	Trees s = #[];
   	if (ts1.length() != ts2.length())
	    return null;
	for ( Trees s1 = ts1, s2 = ts2; !s1.is_empty(); s1=s1.tail(), s2=s2.tail() ) {
	    Tree t = unify(s1.head(),s2.head());
	    if (t == null)
		return null;
	    else s = s.append(t);
	};
	return s;
    }

    static Tree unify ( Tree t1, Tree t2 ) {
	t1 = expand(t1);
	t2 = expand(t2);
        if (t1.equals(#<any>))
	    return t2;
        if (t2.equals(#<any>) || equal_types(t1,t2))
	    return t1;
        match t1 {
	case `T(`t):
	    match t2 {
	    case `S(`s):
		if (!is_collection(T) || !is_collection(S))
		    fail;
		String R = max_collection(T,S);
		Tree r = unify(t,s);
		if (r != null)
		    return #<`R(`r)>;
	    }
	case `f(...ts1):
	    match t2 {
	    case `g(...ts2):
		Trees s = unify(ts1,ts2);
		if (f.equals(g) && s != null)
		    return #<`f(...s)>;
	    }
        };
	return null;
    }

    static Tree unify ( Tree tx, Tree ty, Trees destx, Trees desty ) {
	Tree tp = unify(tx,ty);
	if (tp != null)
	    return tp;
	else if (subtype(tx,ty)) {
	    coerce(tx,ty,destx);
	    return ty;
	} else if (subtype(ty,tx)) {
	    coerce(ty,tx,desty);
	    return tx;
	} else return null;
    }

    static Tree maximum_type ( Trees ts ) {
	Tree maxt = ts.head;
	for ( Tree t: ts.tail )
	    if (subtype(maxt,t) || maxt.equals(#<any>))
		maxt = t;
	return maxt;
    }

    static Tree expand ( Tree tp ) {
	if (!tp.is_variable())
	    return tp;
	Tree rt = global_datatype_env.lookup(tp.toString());
	if (rt != null)
	    return expand(rt);
	rt = type_names.lookup(tp.toString());
	if (rt == null)
	    return tp;
	else return expand(rt);
    }

    static Tree type_inference2 ( Tree e ) {
	return expand(type_inference(e));
    }

    static Tree type_inference ( Tree e ) {
        match e {
	case select(`opt_dist,`u,from(...bl),where(`c),groupby(...gs),orderby(...os)):
	    type_env.begin_scope();
	    Trees dvs = #[];
	    String max_type = "list";
	    for ( Tree b: bl )
		match b {
		case bind(`p,`d):
		    match type_inference2(d) {
		    case `T(`tp):
			if (!is_collection(T))
			    fail;
			dvs = dvs.append(bind_pattern_type(p,tp));
			max_type = max_collection(T,max_type);
		    case `ftp:
			type_error(e,"The from-binding domain "+print_query(d)+" in "
				   +print_query(e)+" must be a collection (found "
				   +print_type(ftp)+")");
		    }
		};
	    Tree ctp = type_inference2(c);
	    if (unify(ctp,#<bool>) == null)
		type_error(e,"The predicate "+print_query(c)+" in "+print_query(e)
			   +" must be a boolean (found "+print_type(ctp)+")");
	    match #<groupby(...gs)> {
	    case groupby(`h,...gl):
		for ( Tree g: gl )
		    match g {
		    case bind(`gp,`gd):
			bind_pattern_type(gp,type_inference2(gd));
		    };
		// lift domain variables to bags
		for ( Tree dv: dvs )
		    type_env.insert(dv.toString(),
				    #<bag(`(type_env.lookup(dv.toString())))>);
		Tree htp = type_inference2(h);
		if (unify(htp,#<bool>) == null)
		    type_error(e,"The group-by predicate "+print_query(h)+" in "+print_query(e)
			       +" must be a boolean (found "+print_type(htp)+")");
	    };
	    match #<orderby(...os)> {
	    case orderby(`l,...ol):
		if (!l.equals(#<none>)) {
		    Tree ltp = type_inference2(l);
		    if (unify(ltp,#<int>) == null)
			type_error(e,"The limit "+print_query(l)+" in "+print_query(e)
				   +" must be an int (found "+print_type(ltp)+")");
		};
		for ( Tree o: ol)
		    type_inference2(o);
		Tree rtp = type_inference2(u);
		type_env.end_scope();
		return (is_persistent_collection(max_type)) ? #<List(`rtp)> : #<list(`rtp)>;
	    };
	    Tree rtp = type_inference2(u);
	    type_env.end_scope();
	    return (is_persistent_collection(max_type)) ? #<Bag(`rtp)> : #<bag(`rtp)>;
	case select(`u,from(...bl),where(`c)):
	    String max_type = "list";
	    for ( Tree b: bl )
		match b {
		case bind(`v,`d):
		    match type_inference2(d) {
		    case `T(`tp):
			if (!is_collection(T))
			    fail;
			type_env.insert(v.toString(),tp);
			max_type = max_collection(T,max_type);
		    case _: type_error(e,"Expected a collection: "+print_query(d)
				       +" in "+print_query(e));
		    }
		};
	    if (unify(type_inference2(c),#<bool>) != null) {
		Tree tp = type_inference(u);
		return (is_persistent_collection(max_type)) ? #<Bag(`tp)> : #<bag(`tp)>;
	    } else type_error(e,"The select predicate must be boolean: "+print_query(e));
	case let_bind(`p,`u,`b):
	    type_env.begin_scope();
	    bind_pattern_type(p,type_inference2(u));
	    Tree tp = type_inference2(b);
	    type_env.end_scope();
	    return tp;
	case let(`p,`u,`b):
	    bind_pattern_type(p,type_inference2(u));
	    return type_inference2(b);
	case case(`u,...cs):
	    Tree tp = type_inference2(u);
	    Trees ts = #[];
	    for ( Tree c: cs )
		match c {
		case case(`p,`b):
		    type_env.begin_scope();
		    bind_pattern_type(p,tp);
		    ts = ts.append(type_inference2(b));
		    type_env.end_scope();
		};
	    Tree maxt = maximum_type(ts);
	    for ( ; cs != #[] && ts != #[]; cs = cs.tail, ts = ts.tail )
		match cs.head {
		case case(`p,`b):
		    if (subtype(ts.head,maxt))
			coerce(ts.head,maxt,((Node)(cs.head)).children.tail);
		    else type_error(cs.head,"Mismatched case output: "+b);
		};
	    return maxt;
	case lambda(`v,`b):
	    if(!v.is_variable())
		fail;
	    if (type_env.lookup(v.toString()) == null)
		type_env.insert(v.toString(),#<any>);
	    return #<arrow(`(type_env.lookup(v.toString())),`(type_inference(b)))>;
	case function(tuple(...params),`outp,`body):
	    Trees as = #[];
	    for ( Tree param: params )
		match param {
		case `bind(`v,`tp):
		    type_env.insert(v.toString(),tp);
		    as = as.append(tp);
		};
	    Tree btp = type_inference(body);
	    if (!subtype(btp,outp))
		type_error(e,"The type of the function body "+print_type(btp)
			   +" does not match the expected type "+print_type(outp)+"\n"+e);
	    if (unify(btp,outp) == null) {  // the body needs coercion
		Trees b = #[`body];
		coerce(btp,outp,b);
		body = b.head;
	    };
	    return #<arrow(tuple(...as),`outp)>;
	case call(source,binary,`f,`tp):
	    return tp;
	case call(source,binary,`f):
	    if (!f.is_string())
		type_error(e,"The source file must be a constant string: "+print_query(f));
	    Tree tp = null;
	    if (Config.hadoop_mode)
		tp = Plan.get_type(f.stringValue());
	    else tp = MapReduceAlgebra.get_type(f.stringValue());
	    if (tp == null)
		type_error(e,"Cannot find the type of file "+f);
	    ((Node)e).children = ((Node)e).children.append(tp);       // destructive
	    return tp;
	case call(source,`parser,`f,...args):
	    if (!parser.is_variable())
		type_error(e,"The parser must be a constant name: "+print_query(parser));
	    if (unify(type_inference(f),#<string>) == null)
		type_error(e,"The source file must be a string: "+print_query(f));
	    try {
		Class<? extends Parser> pc = DataSource.parserDirectory.get(parser.toString());
		if (pc == null)
		    type_error(e,"Unrecognized parser: "+parser);
		Parser p = pc.newInstance();
		p.initialize(args);
		return #<Bag(`(p.type()))>;
	    } catch (Exception x) {
		type_error(e,"Unrecognized parser type: "+parser);
	    }
	case typed(null,`tp):
	    return tp;
	case typed(`f(...),`tp):
	    if (f.equals("tagged_union") || f.equals("union_value"))
		return tp;
	    else fail
	case typed(`x,`tp):
	    if (tp.is_variable() && !tp.equals(#<string>)
		 && MRContainer.type_code(tp.toString()) >= 0) {
	        Tree tx = type_inference(x);
		if (tx.is_variable() && !tx.equals(#<string>)
		     && MRContainer.type_code(tx.toString()) >= 0)
		    return tp;
		else type_error(e,"Expression "+print_query(x)+" of type "+print_type(tx)
				+" cannot be coerced to type "+tp);
	    };
	    Tree tx = type_inference(x);
	    if (!subtype(tx,tp))
		type_error(e,"Expression "+print_query(x)+" of type "+print_type(tx)
			   +" cannot be coerced to type "+print_type(tp));
	    if (unify(tx,tp) == null)   // need to coerce x
		coerce(tx,tp,((Node)e).children);
	    return tp;
	case tuple(...el):
	    Trees s = #[];
	    for ( Tree a: el )
		s = s.append(type_inference(a));
	    return #<tuple(...s)>;
	case call(coerce,`x,`n):
	    return #<`(MRContainer.type_names[(int)n.longValue()])>;
	case record(...el):
	    Trees s = #[];
	    Trees attrs = #[];
	    for ( Tree a: el )
		match a {
		case bind(`v,`b):
		    s = s.append(#<bind(`v,`(type_inference(b)))>);
		    if (attrs.member(v))
			type_error(e,"Duplicate record attribute name: "+v+" in "+print_query(e));
		    attrs = attrs.append(v);
		};
	    return #<record(...s)>;
	case union_tag(`x):
	    return #<int>;
	case `T(...el):
	    if (!is_collection(T))
		fail;
	    if (el.is_empty())
		return #<`T(any)>;
	    Trees ts = #[];
	    for ( Tree t: el )
		ts = ts.append(type_inference(t));
	    Tree maxt = maximum_type(ts);
	    for ( ; el != #[] && ts != #[]; el = el.tail, ts = ts.tail )
		if (subtype(ts.head,maxt))
		    coerce(ts.head,maxt,el);
		else type_error(e,"Incompatible values in "+T+" construction: "+print_query(e));
	    return #<`T(`maxt)>;
	case nth(`a,`n):
	    if (!n.is_long())
		type_error(e,"Tuple index must be an integer: "+print_query(e));
	    int i = (int)n.longValue();
	    match type_inference2(a) {
	    case tuple(...ts):
		if (i < 0 || i >= ts.length())
		    type_error(e,"Tuple index outside bounds: "+print_query(e));
		return ts.nth(i);
	    case `S(tuple(...ts)):
		if (!is_collection(S))
		    fail;
		if (i < 0 || i >= ts.length())
		    type_error(e,"Tuple index outside bounds: "+print_query(e));
		return #<`S(`(ts.nth(i)))>;
	    case `tp:
		type_error(e,"Tuple index must be applied to a tuple: "
			   +print_query(a)+" of type: "+print_type(tp)+" in "+print_query(e));
	    };
	case project(`a,`v):      // highly overloaded
	    Tree ta = type_inference(a);
	    match ta {
	    case XML:
		return #<list(XML)>;
	    case persistent(XML):
		return #<List(XML)>;
	    case `S(XML):
		if (is_collection(S))
		    return #<`S(XML)>;
	    case `S(persistent(XML)):
		if (is_collection(S))
		    return #<`S(persistent(XML))>;
	    };
	    ta = expand(ta);
	    match ta {
	    case record(...ts):
		for ( Tree t: ts )
		    match t {
		    case bind(`w,`tp):
			if (equal_types(w,v))
			    return tp;
		    };
		type_error(e,"Record "+print_query(a)+" does not have a component "+v);
	    case `S(record(...ts)):
		if (!is_collection(S))
		    fail;
		for ( Tree t: ts )
		    match t {
		    case bind(`w,`tp):
			if (equal_types(w,v))
			    return #<`S(`tp)>;
		    };
		type_error(e,"The record collection "+print_query(a)
			   +" does not have a component "+v);
	    case bag(tuple(string,`tv)):
		return tv;
	    case union(...tl):
		Trees s = #[];
		for ( Tree t: tl )
		    match t {
		    case `c(record(...ts)):
			for ( Tree tn: ts )
			    match tn {
			    case bind(`w,`tp):
				if (equal_types(w,v))
				    s = s.append(tp);
			    };
		    case `c(bag(tuple(string,`tv))):
			s = s.append(tv);
		    };
		if (s.length() == 0)
		    type_error(e,"Wrong record projection "+print_query(e)
			       + " over the union "+print_type(ta));
		else if (s.length() > 1)
		    type_error(e,"Ambiguous record projection "+print_query(e)
			       + " over the union "+print_type(ta));
		return s.head();
	    case `t:
		type_error(e,"The record projection "+print_query(e)
			   + " cannot apply to the type "+print_type(t));
	    };
	case index(`a,`i):
	    Tree ti = type_inference2(i);
	    match type_inference2(a) {
	    case `T(tuple(`tk,`tv)):
		if (is_collection(T) && subtype(ti,tk)) {
		    coerce(ti,tk,((Node)e).children.tail);
		    return tv;
		} else fail
	    case list(`tp):
		if (unify(ti,#<int>) != null)
		    return tp;
		else type_error(e,"List index must be an integer: "+print_query(e));
	    case union(...tl):
		Trees s = #[];
		for ( Tree t: tl )
		    match expand(t) {
		    case `c(bag(tuple(`tk,`tv))):
			if (unify(ti,tk) != null)
			    s = s.append(tv);
			else fail
		    case `c(list(`tp)):
			if (unify(ti,#<int>) != null)
			    s = s.append(tp);
			else fail
		    };
		if (s.length() == 0)
		    type_error(e,"Wrong indexing "+print_query(e)
			       + " in union "+print_type(#<union(...tl)>));
		else if (s.length() > 1)
		    type_error(e,"Ambiguous indexing "+print_query(e)
			       + " in union "+print_type(#<union(...tl)>));
		return s.head();
	    case `tp: type_error(e,"Indexing is not allowed for type "+print_type(tp)
				 +" with index "+print_type(ti)+" in "+print_query(e));
	    };
	case range(`u,`i,`j):
	    if (unify(type_inference2(i),#<int>) == null
		|| unify(type_inference2(j),#<int>) == null)
		type_error(e,"Range indexes must be integer expressions: "+print_query(e));
	    match type_inference2(u) {
	    case list(`a): return #<list(`a)>;
	    case List(`a): return #<list(`a)>;
	    };
	    type_error(e,"Range indexing must be applied to a list: "+print_query(e));
	case range(`min,`max):
	    Tree tmin = type_inference(min);
	    Tree tmax = type_inference(max);
	    if (!subtype(tmin,#<long>))
		type_error(e,"Expected a long integer for min: "+print_query(min));
	    else if (unify(tmin,#<long>) == null)  // coerce
		coerce(tmin,#<long>,((Node)e).children);
	    if (!subtype(tmax,#<long>))
		type_error(e,"Expected a long integer for max: "+print_query(max));
	    else if (unify(tmax,#<long>) == null)  // coerce
		coerce(tmax,#<long>,((Node)e).children.tail);
	    return #<list(long)>;
	case call(gen,`min,`max,`size):
	    return type_inference(#<gen(`min,`max,`size)>);
	case gen(`min,`max,`size):
	    Tree tmin = type_inference(min);
	    Tree tmax = type_inference(max);
	    Tree tsize = type_inference(size);
	    if (!subtype(tmin,#<long>))
		type_error(e,"Expected a long integer for min: "+print_query(min));
	    else if (unify(tmin,#<long>) == null)  // coerce
		coerce(tmin,#<long>,((Node)e).children);
	    if (!subtype(tmax,#<long>))
		type_error(e,"Expected a long integer for max: "+print_query(max));
	    else if (unify(tmax,#<long>) == null)  // coerce
		coerce(tmax,#<long>,((Node)e).children.tail);
	    if (!subtype(tsize,#<long>))
		type_error(e,"Expected a long integer for size: "+print_query(size));
	    else if (unify(tsize,#<long>) == null)  // coerce
		coerce(tsize,#<long>,((Node)e).children.tail.tail);
	    return #<Bag(long)>;
	case dataset_size(`x):
	    return #<long>;
	case groupBy(`u):
	    Tree tp = type_inference2(u);
	    match tp {
	    case `T(tuple(`k,`v)):
		if (is_collection(T))
		    return (is_persistent_collection(T))
			    ? #<Bag(tuple(`k,list(`v)))>
			    : #<bag(tuple(`k,list(`v)))>;
	    };
	    type_error(e,"Wrong groupBy: "+print_query(e)+" of type "+print_type(tp));
	case orderBy(`u):
	    Tree tp = type_inference2(u);
	    match tp {
	    case `T(tuple(`k,`v)):
		if (is_collection(T))
		    return (is_persistent_collection(T))
			    ? #<List(tuple(`k,list(`v)))>
			    : #<list(tuple(`k,list(`v)))>;
	    };
	    type_error(e,"Wrong orderBy: "+print_query(e)+" of type "+print_type(tp));
	case cmap(lambda(`v,`body),`s):
	    match type_inference2(s) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		type_env.insert(v.toString(),a);
		match type_inference2(body) {
		case `S(`tp):
		    if (!is_collection(S))
			fail;
		    return #<`T(`tp)>;
		case _: type_error(e,"cmap must return a collection: "+print_query(e));
		};
	    case `t: type_error(e,"cmap must be over a collection: "+print_query(e)
				+"  (found type "+print_type(t)+")");
	    };
	    type_error(e,"Wrong cmap: "+print_query(e));
	case fold(lambda(`v,`body),`n,`s):
	    match type_inference2(s) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		Tree tp = type_inference(n);
		type_env.insert(v.toString(),#<tuple(`a,tp)>);
		if (unify(type_inference2(body),tp) == null)
		    type_error(e,"Wrong types in fold: "+print_query(e));
		return tp;
	    };
	case join(lambda(`v1,`b1),lambda(`v2,`b2),lambda(`vr,`br),`x,`y):
	    match type_inference2(x) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		match type_inference2(y) {
		case `S(`b):
		    if (!is_collection(S))
			fail;
		    type_env.insert(v1.toString(),a);
		    type_env.insert(v2.toString(),b);
		    T = transient_collection(T);
		    S = transient_collection(S);
		    type_env.insert(vr.toString(),#<tuple(`T(`a),`S(`b))>);
		    if (unify(type_inference2(b1),type_inference2(b2)) == null)
			type_error(e,"Incompatible keys in join ("+type_inference2(b1)
				   +" and "+type_inference2(b2)+"): "+print_query(e));
		    match type_inference(br) {
		    case `S3(`ntp):
			if (!is_collection(S3))
			    fail;
			S3 = persistent_collection(S3);
			return #<`S3(`ntp)>;
		    };
		    type_error(e,"The join reducer must return a collection: "+print_query(br));
		case _: type_error(e,"The right join input is not a collection: "+print_query(y));
		};
	    case _: type_error(e,"The left join input is not a collection: "+print_query(x));
	    };
	case crossProduct(lambda(`v1,`b1),lambda(`v2,`b2),lambda(`vr,`br),`x,`y):
	    match type_inference2(x) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		match type_inference2(y) {
		case `S(`b):
		    if (!is_collection(S))
			fail;
		    type_env.insert(v1.toString(),a);
		    type_env.insert(v2.toString(),b);
		    match type_inference2(b1) {
		    case `S1(`w1):
			if (!is_collection(S1))
			    fail;
			match type_inference2(b2) {
			case `S2(`w2):
			    if (!is_collection(S2))
				fail;
			    type_env.insert(vr.toString(),#<tuple(`w1,`w2)>);
			    match type_inference(br) {
			    case `S3(`ntp):
				if (!is_collection(S3))
				    fail;
				S3 = persistent_collection(S3);
				return #<`S3(`ntp)>;
			    };
			    type_error(e,"The cross product reducer must return a collection: "+print_query(br));
			case _: type_error(e,"Wrong right mapper in a cross product: "+print_query(b2));
			};
		    case _: type_error(e,"Wrong left mapper in a cross product: "+print_query(b1));
		    };
		case _: type_error(e,"The right cross product input is not a collection: "+print_query(y));
		};
	    case _: type_error(e,"The left cross product input is not a collection: "+print_query(x));
	    };
	case mapReduce(lambda(`vm,`bm),lambda(`vr,`br),`X,_):
	    match type_inference2(X) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		type_env.insert(vm.toString(),a);
		match type_inference2(bm) {
		case `S(tuple(`k,`b)):
		    if (!is_collection(S))
			fail;
		    type_env.insert(vr.toString(),#<tuple(`k,list(`b))>);
		    match type_inference(br) {
		    case `S3(`ntp):
			if (!is_collection(S3))
			    fail;
			if (is_persistent_collection(T))
			    S3 = persistent_collection(S3);
			return #<`S3(`ntp)>;
		    };
		    type_error(e,"The MapReduce reducer must return a collection: "+print_query(br));
		case _: type_error(e,"Wrong mapper in mapReduce: "+print_query(bm));
		}
	    };
	    type_error(e,"The MapReduce input is not a collection: "+print_query(X));
	case mapReduce2(lambda(`v1,`b1),lambda(`v2,`b2),lambda(`vr,`br),`X,`Y,_):
	    match type_inference2(X) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		match type_inference2(Y) {
		case `S(`b):
		    if (!is_collection(S))
			fail;
		    type_env.insert(v1.toString(),a);
		    type_env.insert(v2.toString(),b);
		    match type_inference2(b1) {
		    case `S1(tuple(`k1,`w1)):
			if (!is_collection(S1))
			    fail;
			match type_inference2(b2) {
			case `S2(tuple(`k2,`w2)):
			    if (!is_collection(S2))
				fail;
			    if (unify(k1,k2) == null)
				type_error(e,"incompatible keys in mapReduce2: "+print_query(e));
			    S1 = transient_collection(S1);
			    S2 = transient_collection(S2);
			    type_env.insert(vr.toString(),#<tuple(`S1(`w1),`S2(`w2))>);
			    match type_inference(br) {
			    case `S3(`ntp):
				if (!is_collection(S3))
				    fail;
				if (is_persistent_collection(T) && is_persistent_collection(S))
				    S3 = persistent_collection(S3);
				return #<`S3(`ntp)>;
			    };
			    type_error(e,"The MapReduce2 reducer must return a collection: "+print_query(br));
			case _: type_error(e,"Wrong right mapper in mapReduce2: "+print_query(b2));
			};
		    case _: type_error(e,"Wrong left mapper in mapReduce2: "+print_query(b1));
		    };
		case _: type_error(e,"The right MapReduce2 input is not a collection: "+print_query(Y));
		};
	    case _: type_error(e,"The left MapReduce2 input is not a collection: "+print_query(X));
	    };
	case Collect(`x):
	    match type_inference2(x) {
	    case Bag(`tp): return #<bag(`tp)>;
	    case List(`tp): return #<list(`tp)>;
	    };
	    type_error(e,"You can only cache persistent collections: "+e);
	case aggregate(lambda(`v,`b),`z,`X):
	    match type_inference2(X) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		Tree ztp = type_inference2(z);
		type_env.insert(v.toString(),#<tuple(`ztp,`a)>);
		if (!subtype(ztp,type_inference2(b)))
		    type_error(e,"Wrong accumulator: "+print_query(e));
		return ztp;
	    };
	    type_error(e,"Aggregation input is not a collection: "+print_query(e));
	case repeat(lambda(`v,`b),`s,...ns):
	    if (!ns.is_empty() && unify(type_inference2(ns.head()),#<int>) == null)
		type_error(e,"The maximum number of steps in repeat must be an integer: "
			   +print_query(ns.head()));
	    match type_inference2(s) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		type_env.insert(v.toString(),#<`T(`a)>);
		match type_inference2(b) {
		case `S(`tp):                         // transitive closure
		    if (!is_collection(S))
			fail;
		    if (unify(a,tp) == null)
			fail;
		    ((Node)e).name = #<closure>.toString();       // destructive
		    return #<`T(`a)>;
		case `S(tuple(`w,`c)):
		    if (!is_collection(S))
			fail;
		    if (unify(c,#<bool>) == null)
			fail;
		    if (unify(a,w) == null)
			fail;
		    return #<`T(`a)>;
		case `tp: type_error(e,"The repeat body must return a collection of type "
				     +print_type(#<`T(`a)>)+" or "+print_type(#<`T(tuple(`a,bool))>)
				     +" (Found type: "+print_type(tp)+")");
		}
	    };
	    type_error(e,"The repeat source must return a bag: "+print_query(e));
	case closure(lambda(`v,`b),`s,...ns):
	    if (!ns.is_empty() && unify(type_inference2(ns.head()),#<int>) == null)
		type_error(e,"The maximum number of steps in closure must be an integer: "
			   +print_query(ns.head()));
	    match type_inference2(s) {
	    case `T(`a):
		if (!is_collection(T))
		    fail;
		type_env.insert(v.toString(),#<`T(`a)>);
		match type_inference2(b) {
		case `S(`tp):
		    if (!is_collection(S))
			fail;
		    if (unify(a,tp) == null)
			fail;
		    return #<`T(`a)>;
		case `tp: type_error(e,"The closure body must return a collection of type "
				     +print_type(#<`T(`a)>)+" or "+print_type(#<`T(tuple(`a,bool))>)
				     +" (Found type: "+print_type(tp)+")");
		}
	    };
	    type_error(e,"The closure source must return a bag: "+print_query(e));
	case step(`x):  // used in QueryPlan for repeat
	    match type_inference(x) {
	    case `T(`tp): return #<`T(tuple(`tp,bool))>;
	    };
	case cstep(`x):  // used in QueryPlan for closure
	    return type_inference(x);
	case if(`p,`x,`y):
	    if (unify(type_inference2(p),#<bool>) == null)
		type_error(e,"Expected a boolean predicate in if-then-else: "+print_query(p));
	    Tree tx = type_inference2(x);
	    Tree ty = type_inference2(y);
	    Tree rt = unify(tx,ty,((Node)e).children.tail,((Node)e).children.tail.tail);
	    if (rt == null)
		type_error(e,"Incompatible types in if-then-else: "+print_query(e));
	    return rt;
	case call(inv,`x):
	    return type_inference(x);
	case call(plus,`x,`y):
	    Tree tx = type_inference2(x);
	    Tree ty = type_inference2(y);
	    match tx {
	    case `T(`xt):
		if (!is_collection(T))
		    fail;
		match ty {
		case `S(`yt):
		    if (!is_collection(S))
			fail;
		    Tree rt = unify(tx,ty,((Node)e).children.tail,((Node)e).children.tail.tail);
		    if (rt == null)
			type_error(e,"Incompatible types in union/append: "+print_type(tx)+" and "+print_type(ty));
		    return rt;
		}
	    };
	    fail
	case `f(`x,`y):
	    if (! #[union,intersect,except].member(#<`f>))
		fail;
	    Tree tx = type_inference2(x);
	    Tree ty = type_inference2(y);
	    match tx {
	    case `T(`t1):
		if (!is_collection(T))
		    fail;
		Tree t = unify(tx,ty,((Node)e).children,((Node)e).children.tail);
		if (t != null)
		    return t;
	    };
	    type_error(e,"Incompatible types in "+f+": "+print_type(tx)+" and "+print_type(ty));
	case call(member,`x,`y):
	    Tree tx = type_inference2(x);
	    Tree ty = type_inference2(y);
	    match ty {
	    case `T(`t1):
		if (!is_collection(T))
		    fail;
		if (!subtype(tx,t1))
		    type_error(e,"Incompatible types in member: "+print_type(tx)+" and "+print_type(ty));
		coerce(tx,t1,((Node)e).children.tail);
		return #<bool>;
	    };
	case call(`f,`x,`y):
	    if (! #[eq,neq,lt,leq,gt,geq].member(f))
		fail;
	    Tree tx = type_inference2(x);
	    Tree ty = type_inference2(y);
	    if (!subtype(tx,ty) && !subtype(ty,tx))
		type_error(e,"Incompatible types in comparison "+f+": "
			   +print_type(tx)+" and "+print_type(ty));
	    if (unify(tx,ty) != null)
		return #<bool>;
	    if (subtype(tx,ty))
		coerce(tx,ty,((Node)e).children.tail);
	    else if (subtype(ty,tx))
		coerce(ty,tx,((Node)e).children.tail.tail);
	    return #<bool>;
	case call(`f,`s):
	    for ( Tree monoid: monoids )
		match monoid {
		case `aggr(`mtp,`plus,`zero,`unit):
		    if (!aggr.equals(f.toString()))
			continue;
		    match type_inference2(s) {
		    case `T(`tp):
			if (!is_collection(T))
			    type_error(e,"Aggregation must be over collections: "+s);
			if (unify(mtp,tp) == null)
			    continue;
			Tree nv = new_var();
			type_env.begin_scope();
			type_env.insert(nv.toString(),tp);
			Tree t = type_inference2(#<apply(`unit,`nv)>);
			Tree tz = type_inference2(zero);
			type_env.end_scope();
			if (unify(t,tz) != null)
			    return t;
		    }
		};
	    fail
	case call(avg,`s):
	    return type_inference(#<call(div,typed(call(sum,`s),double),call(count,`s))>);
	case apply(lambda(`v,`b),`arg):
	    type_env.begin_scope();
	    type_env.insert(v.toString(),type_inference(arg));
	    Tree tp = type_inference(b);
	    type_env.end_scope();
	    return tp;
	case call(`f,...el):
	    if (!f.is_variable() || global_vars.lookup(f.toString()) != null)
		fail;
	    Tree ret = data_constructors.lookup(f.toString());
	    if (ret != null)
		match ret {
		case `v(`n,`tp):
		    if (unify(type_inference(make_tuple(el)),tp) != null)
			return #<`v>;
		    else type_error(e,"Wrong data construction: "+print_query(e));
		};
	    ret = type_env.lookup(f.toString());
	    if (ret == null)
		ret = global_type_env.lookup(f.toString());
	    if (ret != null)
		match ret {
		case arrow(`s,`d):
		    Tree tp = type_inference(#<tuple(...el)>);
		    if (!subtype(tp,s))
			type_error(e,"The domain of the anonymous function "+print_type(s)+" in "+print_query(e)
				   +" does not match the argument types "+print_type(tp));
		    if (unify(tp,s) == null)  // coerce args
			match #<tuple(`tp,`s)> {
			case tuple(tuple(...txs),tuple(...tys)):
			    for ( ; txs != #[]; txs = txs.tail, tys = tys.tail, el = el.tail )
				coerce(txs.head,tys.head,el);
			}
		    return d;
		case _: type_error(e,"Expected a functional type for "+f+" (found "+print_type(ret)+")");
		};
	    Trees tps = #[];
	    for ( Tree a: el )
		tps = tps.append(type_inference(a));
	    for ( Tree fnc: functions )
		match fnc {
		case `fn(`otp,...tl):
		    if (!fn.equals(f.toString()) || !subtype(tps,tl))
			fail;
		    if (f.equals(#<XMLchildren>))
			return #<list(XML)>;
		    else if (f.equals(#<XMLattributes>))
			return #<list(string)>;
		    else if (f.equals(#<XMLattribute>) && collection_type(otp))
			return #<list(string)>;
		    else return otp;
		};
	    type_error(e,"Undefined function "+f+" over arguments of type "+print_type(#<tuple(...tps)>));
	case apply(`f,`u):
	    match type_inference2(f) {
	    case arrow(`s,`d):
		Tree tp = type_inference(u);
		if (!subtype(tp,s))
		    type_error(e,"The domain of the anonymous function "+print_type(s)+" in "+print_query(e)
			       +" does not match the argument types "+print_type(tp));
		if (unify(tp,s) == null)  // coerce args
		    coerce(tp,s,((Node)e).children.tail);
		return d;
	    case `tp: type_error(e,"Expected a functional type for "+f+" (found "+print_type(tp)+")");
	    };
	case callM(`f,_,...el):
	    return type_inference(#<call(`f,...el)>);
	case true: return #<bool>;
	case false: return #<bool>;
	case null: return #<any>;
        case `v:
	    if (!v.is_variable())
		fail;
	    Tree ret1 = type_env.lookup(v.toString());
	    Tree ret2 = global_type_env.lookup(v.toString());
	    if (ret1 == null)
		if (ret2 == null) {
		    Tree ret = global_vars.lookup(v.toString());
		    if (ret == null) {
			String msg = "";
			if (!Config.trace && type_env.iterator().hasNext()) {
			    msg += "\nVariable Types:";
			    for ( String var: type_env )
				msg += "\n "+var + ": " + print_type(type_env.lookup(var));
			};
			type_error(e,"Undefined variable: "+v+msg);
		    } else if (!v.equals(ret))
			return type_inference(ret);
		} else return ret2;
	    else return ret1;
	case `n:
	    if (n.is_long())
	      return #<int>;
	    else if (n.is_double())
		return #<float>;
	    else if (n.is_string())
		return #<string>;
        };
	type_error(e,"Wrong expression: "+print_query(e));
	throw new Error();
    }

    // true if x is functional dependent on y (ie, equal x's implies equal y's)
    static boolean functional_dependent ( Tree x, Tree y ) {
	if (x.equals(y))
	    return true;
	match y {
	case tuple(...ts):
	    for ( Tree t: ts )
		if (functional_dependent(x,t))
		    return true;
	case record(...rs):
	    for ( Tree r: rs )
		match r {
		case bind(_,`t):
		    if (functional_dependent(x,t))
			return true;
		}
	};
	return false;
    }

    // Algebraic normalization (algebra -> algebra)
    static Tree simplify ( Tree e ) {
	match e {
	case cmap(`f,cmap(lambda(`x,`g),`s)):
	    return simplify(#<cmap(lambda(`x,cmap(`f,`g)),`s)>);
	case cmap(`g,join(`k1,`k2,lambda(`p,`f),`X,`Y)):
	    return simplify(#<join(`k1,`k2,lambda(`p,cmap(`g,`f)),`X,`Y)>);
	case cmap(lambda(`x,`S(`y)),`u):
	    if (is_collection(S) && x.equals(y))
		return simplify(u);
	    else fail
	case cmap(lambda(`x,`b),`S(`a)):
	    if (is_collection(S) && x.is_variable())
		return simplify(subst_var(x,a,b));
	    else fail
	case cmap(`f,`S()):
	    if (is_collection(S))
		return #<`S()>;
	    else fail
	case map(lambda(`x,`b),`S(`a)):
	    if (is_collection(S) && x.is_variable())
		return #<`S(`(simplify(subst_var(x,a,b))))>;
	    else fail
	case map(`f,`S()):
	    if (is_collection(S))
		return #<`S()>;
	    else fail
	case filter(lambda(`x,`b),`m,`S(`a)):
	    if (is_collection(S) && x.is_variable())
		return simplify(#<if(`(subst_var(x,a,b)),apply(`m,`a),`S())>);
	    else fail
	case filter(`p,`m,`S()):
	    if (is_collection(S))
		return #<`S()>;
	    else fail
	case cmap(`f,if(`p,`x,`y)):
	    return simplify(#<if(`p,cmap(`f,`x),cmap(`f,`y))>);
	// if the reducer of a join generates pairs (k,v), where k is functional dependent
	// on a join key, then the outer groupBy just groups the v values
	case groupBy(join(lambda(`vx,`bx),`ky,
			  lambda(`v,cmap(lambda(`x,cmap(lambda(`y,bag(tuple(`ex,`br))),
							nth(`v1,1))),
					 nth(`v2,0))),
			  `X,`Y)):
	    if (v1.equals(v) && v2.equals(v) && functional_dependent(subst(vx,x,bx),ex))
		return simplify(#<join(lambda(`vx,`bx),`ky,
				       lambda(`v,groupBy(cmap(lambda(`x,cmap(lambda(`y,bag(tuple(`ex,`br))),
									     nth(`v1,1))),
							      nth(`v2,0)))),
				       `X,`Y)>);
	    fail
	// same for the right key
	case groupBy(join(`kx,lambda(`vy,`by),
			  lambda(`v,cmap(lambda(`x,cmap(lambda(`y,bag(tuple(`ey,`br))),
							nth(`v1,1))),
					 nth(`v2,0))),
			  `X,`Y)):
	    if (v1.equals(v) && v2.equals(v) && functional_dependent(subst(vy,y,by),ey))
		return simplify(#<join(`kx,lambda(`vy,`by),
				       lambda(`v,groupBy(cmap(lambda(`x,cmap(lambda(`y,bag(tuple(`ey,`br))),
									     nth(`v1,1))),
							      nth(`v2,0)))),
				       `X,`Y)>);
	    fail
	// same for the left key, different nesting
	case groupBy(join(lambda(`vx,`bx),`ky,
			  lambda(`v,cmap(lambda(`y,cmap(lambda(`x,bag(tuple(`ex,`br))),
							nth(`v1,0))),
					 nth(`v2,1))),
			  `X,`Y)):
	    if (v1.equals(v) && v2.equals(v) && functional_dependent(subst(vx,x,bx),ex))
		return simplify(#<join(lambda(`vx,`bx),`ky,
				       lambda(`v,groupBy(cmap(lambda(`y,cmap(lambda(`x,bag(tuple(`ex,`br))),
									     nth(`v1,1))),
							      nth(`v2,0)))),
				       `X,`Y)>);
	    fail
	// same for the right key, different nesting
	case groupBy(join(`kx,lambda(`vy,`by),
			  lambda(`v,cmap(lambda(`y,cmap(lambda(`x,bag(tuple(`ey,`br))),
							nth(`v1,0))),
					 nth(`v2,1))),
			  `X,`Y)):
	    if (v1.equals(v) && v2.equals(v) && functional_dependent(subst(vy,y,by),ey))
		return simplify(#<join(`kx,lambda(`vy,`by),
				       lambda(`v,groupBy(cmap(lambda(`y,cmap(lambda(`x,bag(tuple(`ey,`br))),
									     nth(`v1,0))),
							      nth(`v2,1)))),
				       `X,`Y)>);
	    fail
	// same for the left key, right nested
	case groupBy(join(lambda(`vx,`bx),`ky,
			  lambda(`v,cmap(lambda(`x,bag(tuple(`ex,`br))),
					 nth(`v1,0))),
			  `X,`Y)):
	    if (v1.equals(v) && functional_dependent(subst(vx,x,bx),ex))
		return simplify(#<join(lambda(`vx,`bx),`ky,
				       lambda(`v,groupBy(cmap(lambda(`x,bag(tuple(`ex,`br))),
							      nth(`v1,0)))),
				       `X,`Y)>);
	    fail
	// same for the right key, left nested
	case groupBy(join(`kx,lambda(`vy,`by),
			  lambda(`v,cmap(lambda(`y,bag(tuple(`ey,`br))),
					 nth(`v2,1))),
			  `X,`Y)):
	    if (v2.equals(v) && functional_dependent(subst(vy,y,by),ey))
		return simplify(#<join(`kx,lambda(`vy,`by),
				       lambda(`v,groupBy(cmap(lambda(`y,bag(tuple(`ey,`br))),
							      nth(`v2,1)))),
				       `X,`Y)>);
	    fail
	// if we group-by the join key, then embed the group-by in the join reducer
	// (redundant rule)
        case groupBy(join(`kx,`ky,lambda(`v,cmap(lambda(`v1,cmap(lambda(`v2,bag(tuple(`k,`u))),`e1)),`e2)),
			  `X,`Y)):
	    if (((e1.equals(#<nth(`v,0)>) && e2.equals(#<nth(`v,1)>))
		 || (e2.equals(#<nth(`v,0)>) && e1.equals(#<nth(`v,1)>)))
		&& (alpha_equivalent(kx,#<lambda(`v1,`k)>)
		    || alpha_equivalent(kx,#<lambda(`v2,`k)>)))
		return simplify(#<join(`kx,`ky,lambda(`v,groupBy(cmap(lambda(`v1,cmap(lambda(`v2,
									     bag(tuple(`k,`u))),`e1)),`e2))),
				       `X,`Y)>);
	    fail
	case groupBy(groupBy(`x)):
	    Tree nv = new_var();
	    return simplify(#<cmap(lambda(`nv,bag(bag(`nv))),groupBy(`x))>);
	case repeat(lambda(`v,`b),`s,...l):
	    repeat_variables = repeat_variables.cons(v);
	    return #<repeat(lambda(`v,`(simplify(b))),`(simplify(s)),...l)>;
	case closure(lambda(`v,`b),`s,...l):
	    repeat_variables = repeat_variables.cons(v);
	    return #<closure(lambda(`v,`(simplify(b))),`(simplify(s)),...l)>;
	case aggregate(`acc,`zero,`T()):
	    if (is_collection(T))
		return zero;
	    else fail
	case aggregate(`acc,`zero,`T(`s)):
	    if (is_collection(T))
		return simplify(#<apply(`acc,tuple(`zero,`s))>);
	    else fail
	case apply(lambda(`v,`b),`u):
	    if (!v.is_variable())
		fail;
	    return simplify(subst_var(v,u,b));
	case apply(function(tuple(...el),_,`b),`u):
	    int i = 0;
	    for ( Tree a: el )
		match a {
		case `bind(`v,_):
		    b = subst(v,#<nth(`u,`(i++))>,b);
		};
	    return simplify(b);
        case call(and,true,`u): return simplify(u);
        case call(and,`u,true): return simplify(u);
        case call(and,false,`u):return #<false>;
        case call(and,`u,false): return #<false>;
        case call(or,true,`u): return #<true>;
        case call(or,`u,true): return #<true>;
        case call(or,false,`u): return simplify(u);
        case call(or,`u,false): return simplify(u);
	case call(not,true): return #<false>;
	case call(not,false): return #<true>;
	case if(true,`e1,`e2): return simplify(e1);
	case if(false,`e1,`e2): return simplify(e2);
	case call(count,cmap(lambda(`v,`S(`x)),`u)):
	    if (is_collection(S))
	        return simplify(#<call(count,`u)>);
	    else fail
	case call(count,`groupBy(cmap(lambda(`v,`S(tuple(`x,`y))),`u))):
	    if (is_collection(S) && !y.equals(#<0>) && #[groupBy,orderBy].member(#<`groupBy>))
		return #<call(count,groupBy(cmap(lambda(`v,`S(tuple(`x,0))),`u)))>;
	    else fail
	case call(count,`S(...r)):
	    if (is_collection(S))
	        return #<typed(`(r.length()),long)>;
	    else fail
	case call(`f,`S(`x)):
	    if (!is_collection(S))
		fail;
	    for ( Tree m: monoids )
		match m {
		case `aggr(`mtp,`plus,`zero,`unit):
		    if (!aggr.equals(f.toString()))
			continue;
		    if (unify(mtp,type_inference2(x)) != null)
			return simplify(#<apply(`unit,`x)>);
		};
	    fail
	case nth(tuple(...al),`n):
	    if (!n.is_long())
		fail;
	    int i = (int)n.longValue();
	    if (i >= 0 && i < al.length())
		return simplify(al.nth(i));
	case project(record(...bl),`a):
	    for ( Tree b: bl )
		match b {
		case bind(`v,`u):
		    if (v.equals(a))
			return simplify(u);
		};
	case `f(...al):
	    Trees bl = #[];
	    for ( Tree a: al )
		bl = bl.append(simplify(a));
	    return #<`f(...bl)>;
	};
	return e;
    }

    static Tree simplify_all ( Tree e ) {
	Tree ne = simplify(e);
	if (e.equals(ne))
	    return e;
	else return simplify_all(ne);
    }

    static Tree translate_select ( Tree e ) {
       match e {
       case select(`u,from(),where(true)):
	   return #<bag(`(translate_select(u)))>;
       case select(`u,from(),where(`c)):
	   return #<if(`(translate_select(c)),bag(`(translate_select(u))),bag())>;
       case select(`u,from(bind(`v,`d),...bl),where(`c)):
	   Tree n = translate_select(#<select(`u,from(...bl),where(`c))>);
	   return #<cmap(lambda(`v,`n),`(translate_select(d)))>;
       case `f(...al):
	   Trees bl = #[];
	   for ( Tree a: al )
	       bl = bl.append(translate_select(a));
	   return #<`f(...bl)>;
       };
       return e;
    }

    static boolean is_groupBy ( Tree e ) {
	match e {
	case groupBy(...): return true;
	case orderBy(...): return true;
	};
	return false;
    }

    static boolean fits_memory ( Tree e ) {
    	return false;
    }

    // Algebraic optimizations specific to MR (algebra -> algebra)
    static Tree translate ( Tree e ) {
	match e {
	// if the group-by key is the same as the join key, fuse the group-by into the join
	case mapReduce2(lambda(`v,bag(tuple(nth(`v1,0),`mx))),`my,
			lambda(`rv,`rb),
			`groupBy(cmap(lambda(`w,`m),`X)),`Y,`o):
	    if (!v1.equals(v) || !Config.groupJoinOpt || ! #[groupBy,orderBy].member(#<`groupBy>))
		fail;
	    Tree nv = new_var();
	    Tree nr = subst(#<nth(`rv,0)>,#<cmap(lambda(`v,bag(`mx)),groupBy(nth(`rv,0)))>,rb);
	    Tree res = #<mapReduce2(lambda(`w,cmap(lambda(`nv,bag(tuple(nth(`nv,0),`nv))),`m)),
				    `my,lambda(`rv,`nr),`X,`Y,`o)>;
	    res = simplify_all(rename(res));
	    type_inference(res);
	    return translate(res);
	// same for the right join input
	case mapReduce2(`mx,lambda(`v,bag(tuple(nth(`v1,0),`my))),
			lambda(`rv,`rb),
			`X,`groupBy(cmap(lambda(`w,`m),`Y)),`o):
	    if (!v1.equals(v) || !Config.groupJoinOpt || ! #[groupBy,orderBy].member(#<`groupBy>))
		fail;
	    Tree nv = new_var();
	    Tree nr = subst(#<nth(`rv,1)>,#<cmap(lambda(`v,bag(`my)),groupBy(nth(`rv,1)))>,rb);
	    Tree res = #<mapReduce2(`mx,lambda(`w,cmap(lambda(`nv,bag(tuple(nth(`nv,0),`nv))),`m)),
				    lambda(`rv,`nr),`X,`Y,`o)>;
	    res = simplify_all(rename(res));
	    type_inference(res);
	    return translate(res);
        // convert self-joins to single-source mapreduce; Hadoop doesn't like self-joins anyway
	case mapReduce2(lambda(`vx,`bx),lambda(`vy,`by),lambda(`s,`f),`X,`Y,`o):
	    if (!alpha_equivalent(X,Y) || !Config.selfJoinOpt)
		fail;
	    Tree ny = subst(vy,vx,by);
	    Tree tx = null;
	    Tree ty = null;
	    match type_inference(bx) {
	    case _(tuple(_,`t)): tx = t;
	    };
	    match type_inference(by) {
	    case _(tuple(_,`t)): ty = t;
	    };
	    Tree b = subst(s,#<tuple(cmap(lambda(tuple(n,v1,v2),
						 if(call(eq,n,1),bag(v1),bag())),s),
				     cmap(lambda(tuple(n,v1,v2),
						 if(call(eq,n,2),bag(v2),bag())),s))>,
			   f);
	    Tree res = #<mapReduce(lambda(`vx,call(plus,
			     cmap(lambda(x,bag(tuple(nth(x,0),tuple(1,nth(x,1),typed(null,`ty))))),`bx),
				     cmap(lambda(y,bag(tuple(nth(y,0),tuple(2,typed(null,`tx),nth(y,1))))),`ny))),
			   lambda(tuple(k,s),`b),
			   `X,`o)>;
	    res = simplify_all(rename(res));
	    type_inference(res);
	    return translate(res);
	case mapReduce2(`mx,`my,`r,cmap(lambda(`vx,`bx),`X),cmap(lambda(`vy,`by),`Y),`o):
	    return translate(#<mapReduce2(lambda(`vx,cmap(`mx,`bx)),
					  lambda(`vy,cmap(`my,`by)),`r,`X,`Y,`o)>);
	case mapReduce2(`mx,`my,`r,cmap(lambda(`v,`b),`X),`Y,`o):
	    return translate(#<mapReduce2(lambda(`v,cmap(`mx,`b)),`my,`r,`X,`Y,`o)>);
	case mapReduce2(`mx,`my,`r,`X,cmap(lambda(`v,`b),`Y),`o):
	    return translate(#<mapReduce2(`mx,lambda(`v,cmap(`my,`b)),`r,`X,`Y,`o)>);
	case crossProduct(`mx,`my,`r,cmap(lambda(`vx,`bx),`X),cmap(lambda(`vy,`by),`Y)):
	    return translate(#<crossProduct(lambda(`vx,cmap(`mx,`bx)),
					    lambda(`vy,cmap(`my,`by)),`r,`X,`Y)>);
	case crossProduct(`mx,`my,`r,cmap(lambda(`v,`b),`X),`Y):
	    return translate(#<crossProduct(lambda(`v,cmap(`mx,`b)),`my,`r,`X,`Y)>);
	case crossProduct(`mx,`my,`r,`X,cmap(lambda(`v,`b),`Y)):
	    return translate(#<crossProduct(`mx,lambda(`v,cmap(`my,`b)),`r,`X,`Y)>);
	case cmap(`m,crossProduct(`mx,`my,lambda(`v,`b),`X,`Y)):
	    return translate(#<crossProduct(`mx,`my,lambda(`v,cmap(`m,`b)),`X,`Y)>);
	case cmap(`r,`groupBy1(cmap(`m,`groupBy2(`s)))):
	    if (! #[groupBy,orderBy].member(#<`groupBy1>)
		&& ! #[groupBy,orderBy].member(#<`groupBy2>))
		fail;
	    return #<mapReduce(`(identity()),
			       `(translate(r)),
			       `(translate(#<cmap(`m,`groupBy2(`s))>)),
			       `((#<`groupBy1>.equals(#<orderBy>)) ? #<true> : #<false>))>;
	case cmap(`r,`groupBy(cmap(`m,`s))):
	    if (! #[groupBy,orderBy].member(#<`groupBy>))
		fail;
	    return #<mapReduce(`(translate(m)),
			       `(translate(r)),
			       `(translate(s)),
			       `((#<`groupBy>.equals(#<orderBy>)) ? #<true> : #<false>))>;
	case `groupBy(cmap(`m,groupBy(`s))):
	    if (! #[groupBy,orderBy].member(#<`groupBy>))
		fail;
	    return #<mapReduce(`(identity()),
			       `(identity()),
			       `(translate(#<cmap(`m,groupBy(`s))>)),
			       `((#<`groupBy>.equals(#<orderBy>)) ? #<true> : #<false>))>;
	case `groupBy(cmap(`m,`s)):
	    if (! #[groupBy,orderBy].member(#<`groupBy>))
		fail;
	    return #<mapReduce(`(translate(m)),
			       `(identity()),
			       `(translate(s)),
			       `((#<`groupBy>.equals(#<orderBy>)) ? #<true> : #<false>))>;
	case cmap(`r,`groupBy(`s)):
	    if (! #[groupBy,orderBy].member(#<`groupBy>))
		fail;
	    return #<mapReduce(`(identity()),
			       `(translate(r)),
			       `(translate(s)),
			       `((#<`groupBy>.equals(#<orderBy>)) ? #<true> : #<false>))>;
	case `groupBy(`s):
	    if (! #[groupBy,orderBy].member(#<`groupBy>))
		fail;
	    return #<mapReduce(`(identity()),
			       `(identity()),
			       `(translate(s)),
			       `((#<`groupBy>.equals(#<orderBy>)) ? #<true> : #<false>))>;
	case cmap(`m,`s):
	    return #<cmap(`(translate(m)),
			  `(translate(s)))>;
        // convert self-joins to single-source mapreduce; Hadoop doesn't like self-joins anyway
	case join(lambda(`vx,`bx),lambda(`vy,`by),lambda(`s,`f),`x,`y):
	    if (!x.equals(y) || !Config.selfJoinOpt)
		fail;
	    Tree ny = subst(vy,vx,by);
	    Tree b = subst(s,
			    #<tuple(cmap(lambda(tuple(n,v),
						if(call(eq,n,1),bag(v),bag())),s),
				    cmap(lambda(tuple(n,v),
						if(call(eq,n,2),bag(v),bag())),s))>,
				     f);
	    Tree res = #<mapReduce(lambda(`vx,bag(tuple(`bx,tuple(1,`vx)),
						  tuple(`ny,tuple(2,`vx)))),
				   lambda(tuple(k,s),`b),`x,false)>;
	    res = simplify_all(rename(res));
	    type_inference(res);
	    return translate(res);
	case join(lambda(`vx,`bx),lambda(`vy,`by),`f,`x,`y):
	    return translate(#<mapReduce2(lambda(`vx,bag(tuple(`bx,`vx))),
					  lambda(`vy,bag(tuple(`by,`vy))),
					  `f,`x,`y,false)>);
	case nth(`x,`n):
	    match expand(type_inference(x)) {
	    case `S(tuple(...bl)):
		if (!is_collection(S))
		    fail;
		Tree nv = new_var();
		type_env.insert(nv.toString(),bl.nth((int)n.longValue()));
		return translate(#<cmap(lambda(`nv,`S(nth(`nv,`n))),`x)>);
	    };
	    fail
	case project(`x,`a):
	    match expand(type_inference(x)) {
	    case `S(record(...bl)):
		if (!is_collection(S))
		    fail;
		for ( Tree b: bl )
		    match b {
		    case bind(`c,_):
			if (!a.equals(c))
			    fail;
			Tree nv = new_var();
			type_env.insert(nv.toString(),#<record(...bl)>);
			return translate(#<cmap(lambda(`nv,`S(project(`nv,`a))),`x)>);
		    };
	    };
	    fail
	case `f(...al):
	    Trees bl = #[];
	    for ( Tree a: al )
		bl = bl.append(translate(a));
	    return #<`f(...bl)>;
	};
	return e;
    }

    static Tree translate_all ( Tree e ) {
	Tree ne = translate(e);
	if (e.equals(ne))
	    return e;
	else return translate_all(ne);
    }

    static class Aggregates {
	public static Trees maps = #[];
	public static Trees combines = #[];
	public static Trees reduces = #[];
	public static boolean can_use_combiner = true;
	private static SymbolTable st = new SymbolTable();

	public static void clear () {
	    maps = #[];
	    combines = #[];
	    reduces = #[];
	    can_use_combiner = true;
	}

	static int union_aggegates ( Tree reduce, Tree map, Tree combine ) {
	    Tree m = simplify_all(map);
	    Tree c = simplify_all(combine);
	    Tree rd = simplify_all(reduce);
	    int i = 0;
	    for ( Trees r = reduces; !r.is_empty(); r = r.tail(), i++ ) {
		if (alpha_equivalent(rd,r.head()))
		    return i;
	    };
	    maps = maps.append(m);
	    reduces = reduces.append(rd);
	    combines = combines.append(subst(#<-1>,#<`i>,c));
	    return i;
	}

	// generate the MR combiner from the MR reducer
	static Tree derive_combiner ( Tree e, Tree gvar, Tree mvar, Tree map, Tree rvar ) {
	    match e {
	    case call(`f,`u):
		for ( Tree monoid: monoids )
		    match monoid {
		    case `nm(`mtp,`plus,`zero,`unit):
			if (nm.equals(f.toString())) {
			    match type_inference2(u) {
			    case `S(`tp):
				if (unify(tp,mtp) == null)
				    continue;
			    case _: throw new Error("Unexpected aggregation: "+e);
			    };
			    match u {
			    case cmap(`m,`v):
				if (!v.equals(gvar) || occurences(rvar,m) > 0)
				    fail;
				Tree ev = new_var();
				Tree nv = new_var();
				Tree mv = new_var();
				int i = union_aggegates(e,
					   #<aggregate(lambda(`ev,apply(`plus,tuple(nth(`ev,0),apply(`unit,nth(`ev,1))))),
						       `zero,cmap(`m,cmap(lambda(x,bag(nth(x,1))),apply(`map,`mvar))))>,
					   #<aggregate(lambda(`nv,apply(`plus,tuple(nth(`nv,0),
										    nth(nth(`nv,1),-1)))),
						       `zero,`gvar)>);
				return simplify_all(#<aggregate(lambda(`mv,apply(`plus,tuple(nth(`mv,0),
											     nth(nth(`mv,1),`i)))),
								`zero,`gvar)>);
			    case `v:
				if (!v.equals(gvar))
				    fail;
				Tree ev = new_var();
				Tree nv = new_var();
				Tree mv = new_var();
				int i = union_aggegates(e,
					   #<aggregate(lambda(`ev,apply(`plus,tuple(nth(`ev,0),apply(`unit,nth(`ev,1))))),
						       `zero,cmap(lambda(x,bag(nth(x,1))),apply(`map,`mvar)))>,
					   #<aggregate(lambda(`nv,apply(`plus,tuple(nth(`nv,0),nth(nth(`nv,1),-1)))),
						       `zero,`gvar)>);
				return simplify_all(#<aggregate(lambda(`mv,apply(`plus,tuple(nth(`mv,0),
											     nth(nth(`mv,1),`i)))),
								`zero,`gvar)>);
			    }
			}
		    };
		fail
	    case nth(`v,0):
		if (v.is_variable())
		    return e;
		else fail
	    case `f(...al):
		Trees rs = #[];
		for ( Tree a: al )
		    rs = rs.append(derive_combiner(a,gvar,mvar,map,rvar));
		return #<`f(...rs)>;
	    };
	    if (#<nth(`e,1)>.equals(gvar))
		Aggregates.can_use_combiner = false;
	    return e;
	}
    }

    // how many times e accesses the bag x? if it's more than one, it can't be streamed
    static int number_of_accesses ( Tree x, Tree e ) {
	if (e.equals(x))
	    return 1;
	match e {
	case cmap(`m,`s):
	    return number_of_accesses(x,m)*10+number_of_accesses(x,s);
	case map(`m,`s):
	    return number_of_accesses(x,m)*10+number_of_accesses(x,s);
	case filter(`p,`m,`s):
	    return number_of_accesses(x,p)*10+number_of_accesses(x,m)*10+number_of_accesses(x,s);
	case `f(...r):
	    int i = 0;
	    for ( Tree z: r )
		i += number_of_accesses(x,z);
	    return i;
	};
	return 0;
    }

    // can we process the second arg of the MapReducer reducer (a bag) as a stream?
    static boolean streamed_MapReduce_reducer ( Tree x ) {
	match x {
	case lambda(`v,`b):
	    return number_of_accesses(#<nth(`v,1)>,b) <= 1;
	case compiled(_,lambda(`v,`b)):
	    return number_of_accesses(#<nth(`v,1)>,b) <= 1;
	};
	return false;
    }

    // can we process the first arg of the MapReducer2 reducer (a bag) as a stream?
    static boolean streamed_MapReduce2_reducer ( Tree x ) {
	match x {
	case lambda(`v,`b):
	    return number_of_accesses(#<nth(`v,0)>,b) <= 1;
	case compiled(_,lambda(`v,`b)):
	    return number_of_accesses(#<nth(`v,0)>,b) <= 1;
	};
	return false;
    }

    // true if e returns a dataset
    static boolean is_dataset_expr ( Tree e ) {
	match type_inference2(e) {
	case `T(_):
	    if (is_persistent_collection(T))
		return true;
	};
	return false;
    }

    // compile an algebraic form e to a physical plan
    static Tree makePlan ( Tree e ) {
       match e {
       // extract the mapReduce combiner
       case mapReduce(lambda(`vm,`bm),lambda(`vr,`br),`s,`o):
	   if (!Config.use_combiner || !is_dataset_expr(s))
	       fail;
	   Aggregates.clear();
	   Tree nv = new_var();
	   match type_inference(bm) {
	      case `S(`tp):
		  if (!is_collection(S))
		      fail;
		  type_env.insert(nv.toString(),tp);
	   };
	   Tree rd = Aggregates.derive_combiner(br,#<nth(`vr,1)>,vm,#<lambda(`vm,`bm)>,vr);
	   if (Aggregates.can_use_combiner) {
	       Tree m = simplify_all(#<lambda(`vm,cmap(lambda(`nv,bag(tuple(nth(`nv,0),
									    tuple(...(Aggregates.maps))))),`bm))>);
	       Tree c = simplify_all(#<lambda(`vr,bag(tuple(...(Aggregates.combines))))>);
	       Tree r = simplify_all(#<lambda(`vr,`rd)>);
	       type_env.insert(vr.toString(),
	       		       #<tuple(`(type_inference(#<nth(`vr,0)>)),
				       `(type_inference(#<bag(tuple(...(Aggregates.maps)))>)))>);
	       type_inference(m);
	       type_inference(c);
	       type_inference(r);
	       return #<MapCombineReduce(`(makePlan(m)),
					 `(makePlan(c)),
					 `(makePlan(r)),
					 `(makePlan(s)),`o)>;
	   };
	   fail
       case mapReduce(`m,`r,`s,`o):
	   if (is_dataset_expr(s))
	       return #<MapReduce(`(makePlan(m)),
				  `(makePlan(r)),
				  `(makePlan(s)),`o)>;
	   else fail
       case mapReduce2(`mx,`my,`r,`x,`y,`o):
	   if (is_dataset_expr(x) && is_dataset_expr(y) && streamed_MapReduce2_reducer(r))
	       return #<MapReduce2(`(makePlan(mx)),
				   `(makePlan(my)),
				   `(makePlan(r)),
				   `(makePlan(x)),
				   `(makePlan(y)),`o)>;
	   else fail
       case mapReduce2(`mx,`my,lambda(`v,`b),`x,`y,`o):
	   if (!is_dataset_expr(x) || !is_dataset_expr(y))
	       fail;
	   // if the join reducer is not streaming, switch the inputs
	   Tree nv = new_var();
	   Tree nr = subst(#<nth(`v,0)>,#<nth(`nv,1)>,
				     subst(#<nth(`v,1)>,#<nth(`nv,0)>,b));
	   nr = #<lambda(`nv,`nr)>;
	   type_env.insert(nv.toString(),type_inference(#<tuple(nth(`v,1),nth(`v,0))>));
	   return #<MapReduce2(`(makePlan(my)),
			       `(makePlan(mx)),
			       `(makePlan(nr)),
			       `(makePlan(y)),
			       `(makePlan(x)),`o)>;
       case crossProduct(`mx,`my,`r,`x,`y):
	   if (is_dataset_expr(x) && is_dataset_expr(y))
	       return #<CrossProduct(`(makePlan(mx)),
				     `(makePlan(my)),
				     `(makePlan(r)),
				     `(makePlan(x)),
				     `(makePlan(y)))>;
	   else fail
       case cmap(`m,`s):
	   if (is_dataset_expr(s))
	       return #<cMap(`(makePlan(m)),
			     `(makePlan(s)))>;
	   else fail
       case cmap(lambda(`v,if(`p,`T(`u),`S())),`s):
	   if (false && is_collection(T) && is_collection(S))
		   return makePlan(#<filter(lambda(`v,`p),lambda(`v,`u),`s)>);
	   else fail
       case call(source,binary,`file,`tp):
	       return #<BinarySource(`file,`tp)>;
       case call(source,gen,`f,`len,`ulen):
	   return #<SequenceSource(`(makePlan(f)),`(makePlan(len)),
				   `(makePlan(ulen)))>;
       case call(source,`parser,`file,...args):
	   Trees el = #[];
	   for ( Tree a: args )
	       el = el.append(makePlan(a));
	   return #<ParsedSource(`parser,`(makePlan(file)),...el)>;
       case type(`x): return e;
       case gen(`min,`max,`size):
	   return #<Generator(`(makePlan(min)),`(makePlan(max)),`(makePlan(size)))>;
       case repeat(lambda(`v,`b),`s,`n):
	   if (!is_dataset_expr(s))
	       fail;
	   repeat_variables = repeat_variables.cons(v);
	   return #<Repeat(lambda(`v,`(makePlan(b))),`(makePlan(s)),
			   `(makePlan(n)))>;
       case repeat(lambda(`v,`b),`s):
	   if (!is_dataset_expr(s))
	       fail;
	   repeat_variables = repeat_variables.cons(v);
	   return #<Repeat(lambda(`v,`(makePlan(b))),`(makePlan(s)),`(Integer.MAX_VALUE))>;
       case closure(lambda(`v,`b),`s,`n):
	   if (!is_dataset_expr(s))
	       fail;
	   repeat_variables = repeat_variables.cons(v);
	   return #<Closure(lambda(`v,`(makePlan(b))),`(makePlan(s)),
			   `(makePlan(n)))>;
       case closure(lambda(`v,`b),`s):
	   if (!is_dataset_expr(s))
	       fail;
	   repeat_variables = repeat_variables.cons(v);
	   return #<Closure(lambda(`v,`(makePlan(b))),`(makePlan(s)),`(Integer.MAX_VALUE))>;
       case record(...bl):
	   Trees el = #[];
	   for ( Tree b: bl )
	       match b {
	       case bind(_,`c):
		   el = el.append(c);
	       };
	   return makePlan(#<tuple(...el)>);
       case project(`x,`a):
	   Tree tp = type_inference(x);
	   match tp {
	   case XML:
	       return makePlan(#<call(XMLchildren,`(new StringLeaf(a.toString())),`x)>);
	   case persistent(XML):
	       return makePlan(#<call(XMLchildren,`(new StringLeaf(a.toString())),`x)>);
	   case `S(XML):
	       if (is_collection(S))
		   return makePlan(#<call(XMLchildren,`(new StringLeaf(a.toString())),`x)>);
	   case `S(persistent(XML)):
	       if (is_collection(S))
		   return makePlan(#<call(XMLchildren,`(new StringLeaf(a.toString())),`x)>);
	   };
	   match expand(tp) {
	   case record(...bl):
	       int i = 0;
	       for ( Tree b: bl )
		   match b {
		   case bind(`c,_):
		       if (a.equals(c))
			   return makePlan(#<nth(`x,`i)>);
		       else fail
		   case _: i++;
		   };
	   case `T(tuple(string,`tv)):
	       if (is_collection(T))
		   return #<map_index(`(makePlan(x)),
				      `(new StringLeaf(a.toString())))>;
	       else fail
	   case union(...tl):
	       for ( Tree t: tl )
		   match expand(t) {
		   case _(record(...bl)):
		       int i = 0;
		       for ( Tree b: bl )
			   match b {
			   case bind(`c,_):
			       if (a.equals(c))
				   return makePlan(#<nth(union_value(`x),`i)>);
			       else fail
			   case _: i++;
			   };
		   case _(bag(tuple(string,`tv))):
		       return #<map_index(`(makePlan(#<union_value(`x)>)),
					  `(new StringLeaf(a.toString())))>;
		   case `tt: error("wrong projection: "+e+" ("+tt+")");
		   };
	   case `t: error("wrong projection: "+e+" ("+t+")");
	   };
       case typed(`x,`tp):
	   if (tp.is_variable() && !tp.equals(#<string>) && MRContainer.type_code(tp.toString()) >= 0)
	       return makePlan(#<call(coerce,`x,
				       `(MRContainer.type_code(tp.toString())))>);
	   else fail
       case index(`x,`n):
	   match type_inference2(x) {
	   case `T(tuple(`kt,`vt)):
	       if (!is_collection(T))
		   fail;
	       if (type_inference2(n).equals(kt))
		   return #<map_index(`(makePlan(x)),
				      `(makePlan(n)))>;
	   case union(...tl):
	       for ( Tree t: tl )
		   match expand(t) {
		   case _(bag(tuple(`kt,`vt))):
		       if (type_inference2(n).equals(kt))
			   return #<map_index(`(makePlan(#<union_value(`x)>)),
					      `(makePlan(n)))>;
		   case _(list(`tp)):
		       return #<index(`(makePlan(#<union_value(`x)>)),
				      `(makePlan(n)))>;
		   case `tt: error("wrong indexing: "+e+" ("+tt+")");
		   };
	   };
	   return #<index(`(makePlan(x)),
			  `(makePlan(n)))>;
       case call(count,mapReduce(`m,lambda(`vr,`br),`X,`o)):
	   Tree nv = new_var();
	   type_env.insert(nv.toString(),type_inference(vr));
	   Tree nr = simplify(#<lambda(`nv,bag(call(count,`(subst(vr,nv,br)))))>);
	   Tree plan = #<call(sum,mapReduce(`m,`nr,`X,false))>;
	   return makePlan(plan);
       case call(`f,`u):
	   for ( Tree monoid: monoids )
	       match monoid {
	       case `aggr(`mtp,`plus,`zero,`unit):
		   if (aggr.equals(f.toString())) {
		       Tree plan = makePlan(u);
		       Tree nx = new_var();
		       Tree np = new_var();
		       Tree na = new_var();
		       Tree tp = type_inference(e);
		       type_env.insert(np.toString(),#<tuple(`tp,`tp)>);
		       match type_inference(u) {
		       case `T(`t):
			   if (unify(mtp,t) == null)
			       continue;
			   type_env.insert(na.toString(),#<tuple(`tp,`t)>);
			   type_env.insert(nx.toString(),t);
		       };
		       plus = makePlan(simplify_all(#<lambda(`np,apply(`plus,`np))>));
		       Tree acc = makePlan(simplify_all(#<lambda(`na,apply(`plus,tuple(nth(`na,0),
										       apply(`unit,nth(`na,1)))))>));
		       zero = makePlan((f.equals(#<avg>)) ? zero : #<typed(`zero,`tp)>);
		       match plan {
		       case MapReduce(`m,`r,`s,_):
			   plan = #<MapAggregateReduce(`m,`r,`acc,`zero,`s,false)>;
		       case MapReduce2(`mx,`my,`r,`x,`y,_):
			   plan = #<MapAggregateReduce2(`mx,`my,`r,`acc,`zero,`x,`y,false)>;
		       case MapJoin(`kx,`ky,`r,`x,`y):
			   plan = #<MapAggregateJoin(`kx,`ky,`r,`acc,`zero,`x,`y)>;
		       case CrossProduct(`mx,`my,`r,`x,`y):
			   plan = #<CrossAggregateProduct(`mx,`my,`r,`acc,`zero,`x,`y)>;
		       case cMap(`m,`s):
			   plan = #<AggregateMap(`m,`acc,`zero,`s)>;
		       case _:
			   if (is_dataset_expr(u))
			       plan = #<AggregateMap(lambda(`nx,bag(`nx)),`acc,`zero,`plan)>;
			   else return #<aggregate(`acc,`zero,`plan)>;
		       };
		       if (is_dataset_expr(u))
			   return #<Aggregate(`plus,`zero,`plan)>;
		       else return #<aggregate(`plus,`zero,`plan)>;
		   }
	       };
	   fail
       case call(plus,`x,`y):
	   if (!is_dataset_expr(x) || !is_dataset_expr(y))
	       fail;
	   match type_inference2(x) {
	   case `T(_):
	       if (is_collection(T))
		   return #<Merge(`(makePlan(x)),
				  `(makePlan(y)))>;
	   };
	   fail
       case call(`f,...el):
	   if (!f.is_variable())
	       fail;
	   Tree ret = data_constructors.lookup(f.toString());
	   if (ret != null)
	       match ret {
	       case `v(`n,`tp):
		   Tree p = (el.length()==1)
		             ? makePlan(el.head())
		             : makePlan(#<tuple(...el)>);
		   return #<tagged_union(`n,`p)>;
	       };
	   ret = global_type_env.lookup(f.toString());
	   if (ret != null)
	       match ret {
	       case arrow(_,_):
		   Trees args = #[];
		   for ( Tree a: el )
		       args = args.append(makePlan(a));
		   return #<apply(`f,tuple(...args))>;
	       };
	   Trees tps = #[];
	   for ( Tree a: el )
	       tps = tps.append(type_inference(a));
	   int i = ClassImporter.find_method_number(f.toString(),tps);
	   if (i < 0)
	       error("Method "+f+tps+" has no implementation");
	   Trees sig = ClassImporter.signature(i);
	   Trees args = #[];
	   for ( int j = 0; j < el.length(); j++ ) {
	       Tree b = sig.nth(j+1);
	       if (f.equals(#<coerce>) || b.equals(tps.nth(j)) || !b.is_variable()
		   || b.equals(#<union>) || MRContainer.type_code(b.toString()) < 0)
		   args = args.append(makePlan(el.nth(j)));
	       else args = args.append(makePlan(#<call(coerce,`(el.nth(j)),
						       `(MRContainer.type_code(b.toString())))>));
	   };
	   return #<callM(`f,`i,...args)>;
       case let(`v,`u,`body):
	   if (true)
	       fail;   // disable
	   body = makePlan(body);
	   match type_inference(u) {
	   case `S(_):
	       // if a variable bound to a collection is used more than once in the body,
	       // materialize the collection in memory
	       if (is_collection(S) && occurences(v,body) > 1)
		   body = #<let(`v,`(makePlan(#<call(materialize,`v)>)),`body)>;
	   };
	   return #<let(`v,`(makePlan(u)),`body)>;
       case function(tuple(...params),`outp,`body):
	   boolean is_dataset = false;
	   for ( Tree p: params )
	       match p {
	       case dataset(`v,`tp):
		   is_dataset = true;
	       };
	   body = makePlan(body);
	   return #<function(tuple(...params),`outp,`body)>;
       case `f(...al):
	   Trees bl = #[];
	   for ( Tree a: al )
	       bl = bl.append(makePlan(a));
	   return #<`f(...bl)>;
       };
       return e;
    }

    static Trees plans_with_distributed_lambdas
	= #[MapReduce,MapAggregateReduce,MapCombineReduce,
	    MapReduce2,MapAggregateReduce2,MapJoin,MapAggregateJoin,
	    CrossProduct,CrossAggregateProduct,cMap,AggregateMap,BSP,repeat,closure];

    static Trees algebraic_operators
	= #[mapReduce,mapReduce2,cmap,join,groupBy,orderBy,aggregate,map,filter];

    static Trees plan_names = plans_with_distributed_lambdas.append(algebraic_operators)
	                        .append(#[Aggregate,Repeat,Closure,Generator,Let,If]);

    static Tree physical_plan ( Tree plan ) {
	match plan {
	case MapReduce2(`mx,`my,`r,`x,`y,`o):
	    return physical_plan(#<MapAggregateReduce2(`mx,`my,`r,null,null,`x,`y,`o)>);
        // convert a reduce-side join to a fragment-replicate join, if either of the join
        //   inputs is small to fit in memory (dataset sizes are extracted from file statistics)
	case MapAggregateReduce2(`mx,`my,lambda(`v,`b),null,null,`x,`y,false):
	    Tree X = new_var();
	    Tree Y = new_var();
	    Tree nv = new_var();
	    Tree b1 = simplify_all(subst(#<nth(`v,0)>,#<bag(nth(`nv,0))>,
					 subst(#<nth(`v,1)>,#<nth(`nv,1)>,
					       b)));
	    Tree b2 = simplify_all(subst(#<nth(`v,0)>,#<nth(`nv,1)>,
					 subst(#<nth(`v,1)>,#<bag(nth(`nv,0))>,
					       b)));
	    Tree nr = subst(#<nth(`v,0)>,#<nth(`nv,1)>,
			    subst(#<nth(`v,1)>,#<nth(`nv,0)>,
				  b));
	    Tree cond1 = makePlan(#<call(leq,dataset_size(`Y),`(Config.mapjoin_size))>);
	    Tree cond2 = makePlan(#<call(leq,dataset_size(`X),`(Config.mapjoin_size))>);
	    Tree cond3 = makePlan(#<call(lt,dataset_size(`X),dataset_size(`Y))>);
	    return #<Let(`X,`(physical_plan(x)),Let(`Y,`(physical_plan(y)),
			  If(`cond1,
			     MapJoin(`mx,`my,lambda(`nv,`b1),`X,`Y),
			     If(`cond2,
				MapJoin(`my,`mx,lambda(`nv,`b2),`Y,`X),
				If(`cond3,
				   MapAggregateReduce2(`my,`mx,lambda(`nv,`nr),null,null,`Y,`X,false),
				   MapAggregateReduce2(`mx,`my,lambda(`v,`b),null,null,`X,`Y,false))))))>;
	case MapAggregateReduce2(`mx,`my,lambda(`v,`b),`acc,`zero,`x,`y,false):
	    Tree X = new_var();
	    Tree Y = new_var();
	    Tree nv = new_var();
	    Tree nr = subst(#<nth(`v,0)>,#<nth(`nv,1)>,
			    subst(#<nth(`v,1)>,#<nth(`nv,0)>,b));
	    if (!streamed_MapReduce2_reducer(#<lambda(`nv,`nr)>))
		fail;
	    Tree cond = makePlan(#<call(lt,dataset_size(`X),dataset_size(`Y))>);
	    return #<Let(`X,`(physical_plan(x)),Let(`Y,`(physical_plan(y)),
			  If(`cond,
			     MapAggregateReduce2(`my,`mx,lambda(`nv,`nr),`acc,`zero,`Y,`X,false),
			     MapAggregateReduce2(`mx,`my,lambda(`v,`b),`acc,`zero,`X,`Y,false))))>;
	case CrossProduct(`mx,`my,`r,`x,`y):
	    return physical_plan(#<CrossAggregateProduct(`mx,`my,`r,null,null,`x,`y)>);
	case CrossAggregateProduct(`mx,`my,lambda(`v,`b),`acc,`zero,`x,`y):
	    Tree X = new_var();
	    Tree Y = new_var();
	    Tree nv = new_var();
	    Tree nr = subst(#<nth(`v,0)>,#<nth(`nv,1)>,
			    subst(#<nth(`v,1)>,#<nth(`nv,0)>,b));
	    Tree cond = makePlan(#<call(lt,dataset_size(`X),dataset_size(`Y))>);
	    return #<Let(`X,`(physical_plan(x)),Let(`Y,`(physical_plan(y)),
			  If(`cond,
			     CrossAggregateProduct(`my,`mx,lambda(`nv,`nr),`acc,`zero,`Y,`X),
			     CrossAggregateProduct(`mx,`my,lambda(`v,`b),`acc,`zero,`X,`Y))))>;
	case `f(...al):
	    Trees bl = #[];
	    for ( Tree a: al )
		bl = bl.append(physical_plan(a));
	    return #<`f(...bl)>;
	};
	return plan;
    }

    public static boolean contains_plan ( Tree e, Tree v ) {
	match e {
	case lambda(`x,`u): return false;
	case let(...): return false;
	case Let(...): return false;
	case `f(...as):
	    if (plan_names.member(#<`f>) && !free_variables(e,#[]).member(v))
		return true;
	    for (Tree a: as)
		if (contains_plan(a,v))
		    return true;
	    return false;
	};
	return false;
    }

    public static Trees common_factors ( Tree e, Tree v ) {
	match e {
	case lambda(`x,`u): return #[];
	case let(...): return #[];
	case Let(...): return #[];
	case `f(...as):
	    if (!contains_plan(e,v))
		fail;
	    if (plan_names.member(#<`f>) && !free_variables(e,#[]).member(v))
		return #[`e];
	    Trees bs = #[];
	    for ( Tree a: as )
		bs = bs.append(common_factors(a,v));
	    return bs;
	};
	return #[];
    }

    // if a term is used multiple times in a query, factor it out
    public static Tree common_factoring ( Tree e ) {
	match e {
	case `f(...as):
	    if (!plan_names.member(#<`f>))
		fail;
	    Trees bs = #[];
	    Trees binds = #[];
	    for ( Tree a: as )
		match a {
		case lambda(`v,`u):
		    if (!contains_plan(u,v))
			fail;
		    Trees gs = common_factors(u,v);
		    Tree nb = u;
		    for ( Tree g: gs) {
			Tree nv = new_var();
			nb = subst(g,nv,nb);
			binds = binds.append(#<bind(`nv,`g)>);
		    };
		    bs = bs.append(#<lambda(`v,`(common_factoring(nb)))>);
		case _: bs = bs.append(common_factoring(a));
		};
	    Tree res = #<`f(...bs)>;
	    for ( Tree bind: binds )
		match bind {
		case bind(`v,`x):
		    res = #<let(`v,`x,`res)>;
		};
	    return res;
	case `f(...as):
	    Trees bs = #[];
	    for ( Tree a: as )
		bs = bs.append(common_factoring(a));
	    return #<`f(...bs)>;
	};
	return e;
    }

    public static void top_level ( Tree expr ) {
	Interpreter.evaluate_top_level(expr);
    }

    // the list of all direct-access terms (not the results of a bulk operation) that consume a bag;
    static Trees direct_load_consumed = #[];
    //   ... if one of these terms is repeated, then it consumes the bag twice, so it must be materialized
    static Trees to_be_materialized = #[];

    // is this a direct-access term? (not the results of a bulk operation)
    static boolean access_variable ( Tree e ) {
	match e {
	case nth(`x,_):
	    return access_variable(x);
	case union_value(`x):
	    return access_variable(x);
	case index(`x,`n):
	    return access_variable(x);
	case `v:
	    if (v.is_variable())
		return true;
	};
	return false;
    }

    static void materialize_domain ( Tree e, boolean repeated ) {
	if (access_variable(e)) {
	    if ((repeated
		 || direct_load_consumed.member(e))
		&& !to_be_materialized.member(e))
	       to_be_materialized = to_be_materialized.cons(e);
	    direct_load_consumed = direct_load_consumed.cons(e);
	}
    }

    // stream-based bags must be materialized to vectors if accessed more than once
    static void need_materialize ( Tree e, boolean repeated ) {
	match e {
	case let(`v,`x,`y):
	    need_materialize(x,repeated);
	    need_materialize(y,repeated);
	    // remove v from to_be_materialized since it is materialized
	    Trees res = #[];
	    for ( Tree z: to_be_materialized )
		if (!z.equals(v))
		    res = res.append(z);
	    to_be_materialized = res;
	case if(`p,`x,`y):
	    need_materialize(p,repeated);
	    Trees s = to_be_materialized;
	    need_materialize(x,repeated);
	    Trees s1 = to_be_materialized;
	    to_be_materialized = s;
	    need_materialize(y,repeated);
	    // union
	    for ( Tree z: s1 )
		if (!to_be_materialized.member(z))
		    to_be_materialized = to_be_materialized.cons(z);
	case mapReduce(`m,`r,`s,_):
	    need_materialize(m,true);
	    need_materialize(r,true);
	    materialize_domain(s,repeated);
	    need_materialize(s,repeated);
	case `f(...as,`s):
	    if (! #[cmap,map,filter,groupBy,orderBy,aggregate].member(#<`f>))
		fail;
	    for ( Tree a: as )
		need_materialize(a,true);
	    materialize_domain(s,repeated);
	    need_materialize(s,repeated);
	case callM(union,_,`x,`y):
	    materialize_domain(x,repeated);
	    need_materialize(x,repeated);
	    materialize_domain(y,repeated);
	    need_materialize(y,repeated);
	case `f(...as,`x,`y):
	    if (! #[mapReduce2,mapJoin,join,crossProduct].member(#<`f>))
		fail;
	    for ( Tree a: as )
		need_materialize(a,true);
	    materialize_domain(x,repeated);
	    need_materialize(x,repeated);
	    materialize_domain(y,repeated);
	    need_materialize(y,repeated);
	case `f(...as):
	    for ( Tree a: as )
		need_materialize(a,repeated);
	}
    }

    static Tree materialize_terms ( Tree e ) {
	direct_load_consumed = #[];
	to_be_materialized = #[];
	need_materialize(e,false);
	for ( Tree x: to_be_materialized )
	    e = subst(x,#<materialize(`x)>,e);
	return e;
    }
}
